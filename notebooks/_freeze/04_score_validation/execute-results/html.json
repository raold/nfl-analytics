{
  "hash": "9c483b77d4d22b671bca1540ed5827f7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"04 â€“ Score Model Validation: Key Numbers\"\nformat:\n  html:\n    code-fold: true\nexecute:\n  echo: true\n  warning: false\n  message: false\nparams:\n  train_range: [2015, 2023]\n  test_range: [2020, 2024]\n  output_dir: \"analysis/dissertation/figures/out\"\n---\n\n## Goal\nValidate key-number reweighting by testing integer-margin frequencies out-of-sample and reporting teaser EV deltas. Outputs feed Chapter 4.\n\n## 1. Data and helpers\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(DBI)\nlibrary(RPostgres)\nlibrary(glue)\nlibrary(knitr)\n\n# Ensure output_dir is absolute path\noutput_dir <- params$output_dir\nif (!grepl(\"^/\", output_dir)) {\n  output_dir <- file.path(dirname(dirname(getwd())), output_dir)\n}\ndir.create(output_dir, recursive = TRUE, showWarnings = FALSE)\n\nget_games <- function(min_season, max_season) {\n  con <- tryCatch({\n    dbConnect(\n      Postgres(),\n      dbname   = Sys.getenv(\"POSTGRES_DB\", \"devdb01\"),\n      host     = Sys.getenv(\"POSTGRES_HOST\", \"localhost\"),\n      port     = as.integer(Sys.getenv(\"POSTGRES_PORT\", 5544)),\n      user     = Sys.getenv(\"POSTGRES_USER\", \"dro\"),\n      password = Sys.getenv(\"POSTGRES_PASSWORD\", \"sicillionbillions\")\n    )\n  }, error = function(e) NULL)\n  on.exit({ if (!is.null(con)) try(dbDisconnect(con), silent = TRUE) }, add = TRUE)\n  if (is.null(con)) return(NULL)\n  # Detect if total_close exists\n  has_total <- tryCatch({\n    q <- dbGetQuery(con, \"SELECT column_name FROM information_schema.columns WHERE table_name = 'games' AND column_name = 'total_close'\")\n    nrow(q) > 0\n  }, error = function(e) FALSE)\n  sel <- if (has_total) {\n    \"SELECT season, week, game_id, home_score, away_score, spread_close, total_close FROM games WHERE season BETWEEN $1 AND $2\"\n  } else {\n    \"SELECT season, week, game_id, home_score, away_score, spread_close FROM games WHERE season BETWEEN $1 AND $2\"\n  }\n  df <- tryCatch(dbGetQuery(con, sel, params = list(min_season, max_season)), error = function(e) NULL)\n  df\n}\n\nskellam_pmf <- function(d, lambda, mu) {\n  # Skellam pmf using Bessel I_k; fallback to approx if needed\n  b <- suppressWarnings(besselI(2*sqrt(lambda*mu), abs(d)))\n  exp(-(lambda + mu)) * (lambda / mu)^(d/2) * b\n}\n\nreweight_key <- function(pmf, support, keys, targets, moment_preserve = TRUE, iters = 200) {\n  # Iterative proportional fitting to match key targets on an aggregated pmf.\n  # Returns a global weight vector w_d applied to any game's pmf over the same support.\n  w <- rep(1, length(pmf))\n  idx <- match(keys, support, nomatch = 0)\n  base <- pmf / sum(pmf)\n  for (it in seq_len(iters)) {\n    p <- base * w; p <- p / sum(p)\n    for (j in seq_along(keys)) {\n      k <- idx[j]\n      if (k > 0 && p[k] > 0) {\n        ratio <- targets[j] / p[k]\n        w[k] <- w[k] * ratio\n      }\n    }\n    w <- pmax(w, 1e-8)\n    if (moment_preserve) {\n      p <- base * w; p <- p / sum(p)\n      m <- sum(support * p); s2 <- sum((support - m)^2 * p)\n      m0 <- sum(support * base); s20 <- sum((support - m0)^2 * base)\n      # small blend toward baseline moments\n      alpha <- 0.2\n      target_m <- (1 - alpha) * m0 + alpha * m\n      target_s2 <- (1 - alpha) * s20 + alpha * s2\n      # Correct first moment by distributing mass linearly near center\n      delta_m <- target_m - m\n      w <- w * (1 + 0.0005 * (support - m) * sign(delta_m))\n      # Correct variance by gently widening/narrowing\n      delta_s <- target_s2 - s2\n      w <- w * (1 + 0.0005 * ((support - m)^2) * sign(delta_s))\n    }\n  }\n  w / sum(base * w)  # normalize so that sum(base * w) = 1\n}\n```\n:::\n\n\n## 2. Fit baseline Skellam on train; evaluate on test\n\n::: {.cell}\n\n```{.r .cell-code}\ngames <- get_games(min(params$train_range), max(params$test_range))\n\nif (is.null(games) || nrow(games) == 0) {\n  message(\"No DB; writing placeholder tables/figures.\")\n  # Placeholder chi-square table\n  ks <- data.frame(Model = c(\"Skellam (baseline)\", \"Skellam + reweight\"), Chisq = NA_real_, p_value = NA_real_)\n  writeLines(knitr::kable(ks, format = \"latex\", booktabs = TRUE, caption = \"Chi-square at key margins (placeholder).\", col.names = c(\"Model\", \"$\\\\chi^2$\", \"p-value\")),\n             con = file.path(output_dir, \"keymass_chisq_table.tex\"))\n  # Placeholder teaser EV table\n  tev <- data.frame(Model = c(\"Skellam (baseline)\", \"Skellam + reweight\"), Mean_EV_bps = NA_real_, ROI = NA_real_)\n  writeLines(knitr::kable(tev, format = \"latex\", booktabs = TRUE, caption = \"Teaser EV/ROI (placeholder).\"),\n             con = file.path(output_dir, \"teaser_ev_oos_table.tex\"))\n  # Placeholder ablation table\n  abl <- data.frame(Config = c(\"without reweighting\", \"with reweighting\"), Brier = NA_real_, ATS_acc = NA_real_)\n  writeLines(knitr::kable(abl, format = \"latex\", booktabs = TRUE, caption = \"With/without reweighting ablation (placeholder).\"),\n             con = file.path(output_dir, \"reweighting_ablation_table.tex\"))\n  # Placeholder figure\n  png(file.path(output_dir, \"integer_margin_calibration.png\"), width = 900, height = 500)\n  plot.new(); text(0.5, 0.5, \"Placeholder: integer-margin calibration\")\n  dev.off()\n} else {\n  games <- games |> mutate(margin = home_score - away_score,\n                           total_obs = home_score + away_score)\n  train <- games |> filter(season >= params$train_range[1], season <= params$train_range[2])\n  test  <- games |> filter(season >= params$test_range[1],  season <= params$test_range[2])\n\n  # Use total_close if available; otherwise use season-average observed total from train\n  season_total_mean <- train |>\n    group_by(season) |>\n    summarise(total_mean = mean(total_obs, na.rm = TRUE), .groups = \"drop\")\n  test <- test |>\n    left_join(season_total_mean, by = \"season\") |>\n    mutate(total_close = ifelse(!is.na(total_close), total_close, total_mean))\n\n  # Per-game Skellam parameters using spread and total\n  # margin mean = lambda - mu = spread_close; total mean = lambda + mu = total_close\n  # solve: lambda = (total + spread)/2, mu = (total - spread)/2\n  test <- test |>\n    mutate(lambda = pmax((total_close + spread_close)/2, 1e-6),\n           mu     = pmax((total_close - spread_close)/2, 1e-6))\n\n  support <- -40:40\n\n  # Aggregate baseline pmf over train (league-level) for reweighting targets\n  # Compute empirical key targets from train\n  keys <- c(3,6,7,10)\n  key_targets <- sapply(keys, function(k) mean(train$margin == k))\n\n  # Baseline aggregate pmf from train using season-level lambdas as proxy\n  lam_tr <- mean(train$home_score); mu_tr <- mean(train$away_score)\n  pmf_train_base <- skellam_pmf(support, lam_tr, mu_tr); pmf_train_base <- pmf_train_base / sum(pmf_train_base)\n\n  # Compute global key weights w_d from train\n  w_d <- reweight_key(pmf_train_base, support, keys, key_targets)\n\n  # Per-game predicted pmfs on test\n  pmf_mat_base <- sapply(1:nrow(test), function(i) {\n    p <- skellam_pmf(support, test$lambda[i], test$mu[i]); p / sum(p)\n  })\n  pmf_mat_rw <- (pmf_mat_base * w_d) # broadcast w_d across columns\n  pmf_mat_rw <- sweep(pmf_mat_rw, 2, colSums(pmf_mat_rw), FUN = \"/\")\n\n  # Aggregate predicted probabilities at keys (expected counts)\n  idx_keys <- match(keys, support)\n  exp_counts_base <- colSums(matrix(pmf_mat_base[idx_keys, , drop = FALSE], nrow = length(keys)))\n  exp_counts_base <- sum(pmf_mat_base[idx_keys, ])  # sum over all games -> expected count across dataset\n  exp_counts_rw   <- sum(pmf_mat_rw[idx_keys, ])\n  # Observed counts at keys\n  obs_counts <- sapply(keys, function(k) sum(test$margin == k))\n  obs_total_keys <- sum(obs_counts)\n\n  # Chi-square using game-wise expected counts at keys\n  # Compute expected counts per key separately\n  exp_counts_base_vec <- sapply(1:length(keys), function(j) sum(pmf_mat_base[idx_keys[j], ]))\n  exp_counts_rw_vec   <- sapply(1:length(keys), function(j) sum(pmf_mat_rw[idx_keys[j], ]))\n\n  chisq_stat <- function(obs, exp) {\n    exp <- pmax(exp, 1e-6)\n    sum((obs - exp)^2 / exp)\n  }\n  cs_base <- chisq_stat(obs_counts, exp_counts_base_vec)\n  cs_rw   <- chisq_stat(obs_counts, exp_counts_rw_vec)\n  p_base <- pchisq(cs_base, df = length(keys) - 1, lower.tail = FALSE)\n  p_rw   <- pchisq(cs_rw,   df = length(keys) - 1, lower.tail = FALSE)\n\n  ks <- tibble(Model = c(\"Skellam (baseline)\", \"Skellam + reweight\"), `\\\\(\\\\chi^2\\\\)` = c(round(cs_base,2), round(cs_rw,2)), `p-value` = c(round(p_base,3), round(p_rw,3)))\n  writeLines(knitr::kable(ks, format = \"latex\", booktabs = TRUE, caption = \"Chi-square at key margins (holdout).\"),\n             con = file.path(output_dir, \"keymass_chisq_table.tex\"))\n\n  # Integer-margin calibration figure (aggregated)\n  agg_base <- rowMeans(pmf_mat_base)\n  agg_rw   <- rowMeans(pmf_mat_rw)\n  obs_tbl <- as.data.frame(table(factor(test$margin, levels = support))) |>\n    rename(d = Var1, n = Freq) |>\n    mutate(d = as.integer(as.character(d)), obs = n / sum(n))\n  df_plot <- tibble(d = support, baseline = agg_base, reweighted = agg_rw) |>\n    filter(d >= -20 & d <= 20) |>\n    pivot_longer(-d, names_to = \"model\", values_to = \"p\")\n  p <- ggplot(df_plot, aes(x = d, y = p, color = model)) +\n    geom_line() + geom_point(data = obs_tbl |> filter(d >= -20 & d <= 20), aes(x = d, y = obs), inherit.aes = FALSE, color = \"black\", size = 1) +\n    geom_vline(xintercept = keys, linetype = \"dashed\", alpha = 0.2) +\n    labs(x = \"Margin d\", y = \"Probability\", title = \"Integer-margin calibration (holdout)\") +\n    theme_minimal(base_size = 12)\n  ggsave(file.path(output_dir, \"integer_margin_calibration.png\"), p, width = 9, height = 5, dpi = 200)\n\n  # ATS/Brier using pmfs\n  p_cover_base <- colSums(sapply(1:nrow(test), function(i) as.numeric(support + test$spread_close[i] > 0) * pmf_mat_base[, i]))\n  p_cover_rw   <- colSums(sapply(1:nrow(test), function(i) as.numeric(support + test$spread_close[i] > 0) * pmf_mat_rw[, i]))\n  y_cover      <- as.integer(test$margin + test$spread_close > 0)\n  brier <- function(p,y) mean((p - y)^2)\n  ats_acc <- function(p,y) mean(ifelse(p >= 0.5, 1, 0) == y)\n  abl <- tibble(\n    Config = c(\"without reweighting\", \"with reweighting\"),\n    Brier = c(round(brier(p_cover_base, y_cover), 4), round(brier(p_cover_rw, y_cover), 4)),\n    ATS_acc = c(round(ats_acc(p_cover_base, y_cover), 3), round(ats_acc(p_cover_rw, y_cover), 3))\n  )\n  writeLines(knitr::kable(abl, format = \"latex\", booktabs = TRUE, caption = \"With/without reweighting ablation (ATS/Brier on holdout).\"),\n             con = file.path(output_dir, \"reweighting_ablation_table.tex\"))\n\n  # Teaser EV (independence approximation): 2-leg, 6-point, d = 1.8\n  d_pay <- 1.8\n  s_tease <- test$spread_close + 6  # tease home side favorably\n  q_base <- colSums(sapply(1:nrow(test), function(i) as.numeric(support + s_tease[i] > 0) * pmf_mat_base[, i]))\n  q_rw   <- colSums(sapply(1:nrow(test), function(i) as.numeric(support + s_tease[i] > 0) * pmf_mat_rw[, i]))\n  ev2_base <- d_pay * mean(q_base^2) - 1\n  ev2_rw   <- d_pay * mean(q_rw^2) - 1\n  tev <- tibble(Model = c(\"Skellam (baseline)\", \"Skellam + reweight\"), `Mean EV (bps)` = round(c(ev2_base, ev2_rw) * 10000, 1), ROI = NA_real_)\n  writeLines(knitr::kable(tev, format = \"latex\", booktabs = TRUE, caption = \"Two-leg teaser EV (independence approx.) on holdout).\"),\n             con = file.path(output_dir, \"teaser_ev_oos_table.tex\"))\n}\n```\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
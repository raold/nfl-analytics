{
  "hash": "45782c00eca70d4754f313d83a0b06e1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"00 – Timeframe Ablation\"\nformat:\n  html:\n    code-fold: true\nexecute:\n  echo: true\n  warning: false\n  message: false\nparams:\n  eval_season: 2024\n  half_lives: [3, 4, 5]\n  recent_start: 2015\n  full_start: 1999\n  train_end: 2023\n  output_dir: \"analysis/dissertation/figures/out\"\n---\n\n## Overview\nThis notebook produces the exhibits used to justify the analysis timeframe and era‑weighting strategy:\n\n- Weight vs season curve for half‑lives `H ∈ {3,4,5}` and an ESS table.\n- Rolling out‑of‑sample (blocked TSCV) performance comparing recent‑only vs decayed‑full training.\n- 2024 head‑to‑head Diebold–Mariano‑style comparison and reliability curves.\n\nIt assumes a local TimescaleDB with a `games` table containing final scores and closing spreads. If the connection fails, the notebook will still render the weighting/ESS figures and write placeholder tables.\n\n## 1. Decay Weights and ESS\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(readr)\nlibrary(purrr)\nlibrary(knitr)\nlibrary(glue)\n\ndir.create(params$output_dir, recursive = TRUE, showWarnings = FALSE)\n\nexp_weight <- function(s, t, H) 0.5 ^ ((t - s) / H)\n\nseasons <- seq(params$full_start, params$eval_season)\n\nweights_df <- expand_grid(season = seasons, H = params$half_lives) |>\n  mutate(weight = exp_weight(season, params$eval_season, H))\n\np <- ggplot(weights_df, aes(x = season, y = weight, color = factor(H))) +\n  geom_line(linewidth = 1) +\n  geom_point(data = subset(weights_df, season %in% c(min(seasons), params$eval_season)), size = 2) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 0.1)) +\n  scale_color_brewer(palette = \"Set1\", name = \"Half-life (H)\") +\n  labs(x = \"Season\", y = \"Relative weight vs eval season\",\n       title = glue(\"Exponential decay weights centered on {params$eval_season}\")) +\n  theme_minimal(base_size = 12)\n\nggsave(filename = file.path(params$output_dir, \"time_decay_weights.png\"), plot = p,\n       width = 8, height = 4.5, dpi = 200)\n\n# ESS in season-units (assumes 1 equal-mass observation per season)\ness_tbl <- weights_df |>\n  group_by(H) |>\n  summarise(\n    sum_w = sum(weight),\n    sum_w2 = sum(weight^2),\n    ess = (sum_w^2) / sum_w2,\n    .groups = \"drop\"\n  ) |>\n  mutate(ess = round(ess, 1))\n\ness_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n      H sum_w sum_w2   ess\n  <int> <dbl>  <dbl> <dbl>\n1     3  4.84   2.70   8.7\n2     4  6.22   3.41  11.3\n3     5  7.51   4.13  13.7\n```\n\n\n:::\n\n```{.r .cell-code}\n# Write a LaTeX table that the dissertation includes conditionally\ness_tex <- knitr::kable(\n  ess_tbl,\n  format = \"latex\",\n  booktabs = TRUE,\n  caption = \"Effective sample size (season units) under exponential decay centered on the evaluation season.\",\n  col.names = c(\"Half-life H\", \"$\\\\sum w$\", \"$\\\\sum w^2$\", \"ESS (seasons)\")\n)\nwriteLines(ess_tex, con = file.path(params$output_dir, \"ess_table.tex\"))\n```\n:::\n\n\n## 2. Assemble Data (scores and spreads)\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DBI)\nlibrary(RPostgres)\n\nget_games <- function() {\n  con <- tryCatch({\n    dbConnect(\n      Postgres(),\n      dbname   = Sys.getenv(\"POSTGRES_DB\", \"devdb01\"),\n      host     = Sys.getenv(\"POSTGRES_HOST\", \"localhost\"),\n      port     = as.integer(Sys.getenv(\"POSTGRES_PORT\", 5544)),\n      user     = Sys.getenv(\"POSTGRES_USER\", \"dro\"),\n      password = Sys.getenv(\"POSTGRES_PASSWORD\", \"sicillionbillions\")\n    )\n  }, error = function(e) NULL)\n\n  on.exit({ if (!is.null(con)) try(dbDisconnect(con), silent = TRUE) }, add = TRUE)\n\n  if (is.null(con)) return(NULL)\n\n  sql <- \"SELECT season, week, game_id, home_team, away_team, home_score, away_score, spread_close\n          FROM games\n          WHERE season BETWEEN $1 AND $2\"\n  res <- tryCatch(dbGetQuery(con, sql, params = list(params$full_start, params$eval_season)), error = function(e) NULL)\n  res\n}\n\ngames <- get_games()\n\nif (is.null(games) || nrow(games) == 0) {\n  message(\"No DB connection or empty result. Proceeding with placeholders for modeling figures.\")\n} else {\n  games <- games |>\n    mutate(\n      margin = home_score - away_score,\n      spread_target = if_else(!is.na(spread_close), as.integer(margin + spread_close > 0), NA_integer_)\n    ) |>\n    filter(!is.na(spread_target), !is.na(spread_close))\n}\n```\n:::\n\n\n## 3. Rolling TSCV: recent-only vs decayed-full\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(broom)\n\ncalc_ece <- function(y, p, bins = 10) {\n  df <- tibble(y = y, p = p) |>\n    mutate(bin = cut(p, breaks = seq(0, 1, length.out = bins + 1), include.lowest = TRUE)) |>\n    group_by(bin) |>\n    summarise(\n      n = n(),\n      p_hat = mean(p),\n      y_bar = mean(y),\n      .groups = \"drop\"\n    ) |>\n    filter(n > 0)\n  # Expected Calibration Error (ECE)\n  sum((df$n / sum(df$n)) * abs(df$p_hat - df$y_bar))\n}\n\ntrain_glm_weighted <- function(df, train_years, t_eval, H = NULL, recent_only_start = NULL) {\n  dtr <- df |>\n    dplyr::filter(season %in% train_years)\n  if (!is.null(recent_only_start)) {\n    # Only apply recent_only filter if we have overlap with train years\n    if (max(train_years) >= recent_only_start) {\n      dtr <- dtr |>\n        dplyr::filter(season >= recent_only_start)\n    }\n  }\n  if (nrow(dtr) == 0) return(NULL)\n  if (is.null(H)) {\n    dtr$sw <- 1\n  } else {\n    dtr$sw <- exp_weight(dtr$season, t_eval, H)\n  }\n  suppressWarnings(glm(spread_target ~ spread_close, data = dtr, family = binomial(), weights = sw))\n}\n\npredict_metrics <- function(mod, dte) {\n  if (is.null(mod) || is.null(dte) || nrow(dte) == 0) return(NULL)\n  p <- as.numeric(predict(mod, dte, type = \"response\"))\n  y <- dte$spread_target\n  ll <- - (y * log(p + 1e-15) + (1 - y) * log(1 - p + 1e-15))\n  tibble(p = p, y = y, ll = ll)\n}\n\nwindows <- list(\n  list(train = 1999:2010, test = 2011:2014),\n  list(train = 2011:2014, test = 2015:2018),\n  list(train = 2015:2018, test = 2019:2021),\n  list(train = 2019:2021, test = 2022:2024)\n)\n\nrolling_metrics <- NULL\n\nif (!is.null(games) && nrow(games) > 0) {\n  cat(\"Starting rolling TSCV with\", nrow(games), \"games\\n\")\n\n  rolling_metrics <- purrr::map_dfr(windows, function(w) {\n    tr_years <- w$train\n    te_years <- w$test\n    t_eval <- max(te_years)\n    dte <- games |> dplyr::filter(season %in% te_years)\n\n    cat(\"Window:\", min(tr_years), \"-\", max(tr_years), \"→\", min(te_years), \"-\", max(te_years), \"| Test games:\", nrow(dte), \"\\n\")\n\n    # Skip if no test data\n    if (nrow(dte) == 0) {\n      cat(\"  Skipping: no test data\\n\")\n      return(NULL)\n    }\n\n    mod_rec <- train_glm_weighted(games, train_years = tr_years, t_eval = t_eval, H = NULL, recent_only_start = params$recent_start)\n    mod_dec3 <- train_glm_weighted(games, train_years = tr_years, t_eval = t_eval, H = 3)\n    mod_dec4 <- train_glm_weighted(games, train_years = tr_years, t_eval = t_eval, H = 4)\n    mod_dec5 <- train_glm_weighted(games, train_years = tr_years, t_eval = t_eval, H = 5)\n\n    m_rec <- predict_metrics(mod_rec, dte)\n    m_dec3 <- predict_metrics(mod_dec3, dte)\n    m_dec4 <- predict_metrics(mod_dec4, dte)\n    m_dec5 <- predict_metrics(mod_dec5, dte)\n\n    # Skip if any predictions failed\n    if (is.null(m_rec) || is.null(m_dec3) || is.null(m_dec4) || is.null(m_dec5)) {\n      cat(\"  Skipping: model predictions failed\\n\")\n      return(NULL)\n    }\n\n    tibble(\n      block = glue(\"{min(te_years)}–{max(te_years)}\"),\n      model = c(\"recent\", \"decH3\", \"decH4\", \"decH5\"),\n      logloss = c(mean(m_rec$ll), mean(m_dec3$ll), mean(m_dec4$ll), mean(m_dec5$ll)),\n      ece = c(calc_ece(m_rec$y, m_rec$p), calc_ece(m_dec3$y, m_dec3$p), calc_ece(m_dec4$y, m_dec4$p), calc_ece(m_dec5$y, m_dec5$p))\n    )\n  })\n\n  cat(\"\\n=== Rolling metrics result ===\\n\")\n  print(rolling_metrics)\n  cat(\"Dimensions:\", if(!is.null(rolling_metrics)) nrow(rolling_metrics) else 0, \"rows\\n\\n\")\n\n  # Only plot if we have data\n  if (!is.null(rolling_metrics) && nrow(rolling_metrics) > 0) {\n    # Plot rolling log loss\n    p_ll <- ggplot(rolling_metrics, aes(x = block, y = logloss, color = model, group = model)) +\n      geom_line(linewidth = 1) + geom_point() +\n      labs(x = \"Evaluation block\", y = \"Log loss (mean)\", color = \"Model\") +\n      theme_minimal(base_size = 12)\n    ggsave(file.path(params$output_dir, \"rolling_oos_logloss.png\"), p_ll, width = 8, height = 4.5, dpi = 200)\n    cat(\"Saved rolling_oos_logloss.png\\n\")\n\n    # Plot rolling ECE\n    p_ece <- ggplot(rolling_metrics, aes(x = block, y = ece, color = model, group = model)) +\n      geom_line(linewidth = 1) + geom_point() +\n      labs(x = \"Evaluation block\", y = \"ECE (10 bins)\", color = \"Model\") +\n      theme_minimal(base_size = 12)\n    ggsave(file.path(params$output_dir, \"rolling_oos_ece.png\"), p_ece, width = 8, height = 4.5, dpi = 200)\n    cat(\"Saved rolling_oos_ece.png\\n\")\n  } else {\n    cat(\"WARNING: rolling_metrics is NULL or empty - skipping plots\\n\")\n  }\n}\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStarting rolling TSCV with 6991 games\nWindow: 1999 - 2010 → 2011 - 2014 | Test games: 1068 \nWindow: 2011 - 2014 → 2015 - 2018 | Test games: 1068 \nWindow: 2015 - 2018 → 2019 - 2021 | Test games: 821 \nWindow: 2019 - 2021 → 2022 - 2024 | Test games: 854 \n\n=== Rolling metrics result ===\n# A tibble: 16 × 4\n   block     model  logloss    ece\n   <glue>    <chr>    <dbl>  <dbl>\n 1 2011–2014 recent   0.475 0.0457\n 2 2011–2014 decH3    0.475 0.0356\n 3 2011–2014 decH4    0.475 0.0352\n 4 2011–2014 decH5    0.475 0.0350\n 5 2015–2018 recent   0.479 0.0422\n 6 2015–2018 decH3    0.479 0.0388\n 7 2015–2018 decH4    0.479 0.0391\n 8 2015–2018 decH5    0.479 0.0393\n 9 2019–2021 recent   0.493 0.0760\n10 2019–2021 decH3    0.494 0.0765\n11 2019–2021 decH4    0.493 0.0764\n12 2019–2021 decH5    0.493 0.0763\n13 2022–2024 recent   0.480 0.0410\n14 2022–2024 decH3    0.481 0.0420\n15 2022–2024 decH4    0.480 0.0417\n16 2022–2024 decH5    0.480 0.0416\nDimensions: 16 rows\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSaved rolling_oos_logloss.png\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSaved rolling_oos_ece.png\n```\n\n\n:::\n:::\n\n\n## 4. 2024 Head-to-Head and Reliability\n\n::: {.cell}\n\n```{.r .cell-code}\ndm_t_test <- function(loss_recent, loss_decayed) {\n  d <- loss_recent - loss_decayed\n  tt <- t.test(d, alternative = \"two.sided\")\n  tibble(delta_mean = mean(d), p_value = tt$p.value)\n}\n\ndm_results <- NULL\n\nif (!is.null(games) && nrow(games) > 0) {\n  holdout <- games |> filter(season == params$eval_season)\n  tr_years <- params$full_start:params$train_end\n\n  mod_rec <- train_glm_weighted(games, train_years = tr_years, t_eval = params$eval_season, H = NULL, recent_only_start = params$recent_start)\n  mod_dec <- lapply(params$half_lives, function(H) train_glm_weighted(games, train_years = tr_years, t_eval = params$eval_season, H = H))\n  names(mod_dec) <- paste0(\"H\", params$half_lives)\n\n  m_rec <- predict_metrics(mod_rec, holdout)\n  m_list <- lapply(mod_dec, predict_metrics, dte = holdout)\n\n  dm_results <- purrr::imap_dfr(m_list, function(m, name) {\n    out <- dm_t_test(m_rec$ll, m$ll)\n    out$model <- paste0(\"decayed-\", name)\n    out\n  }) |>\n    relocate(model)\n\n  # Reliability curves\n  rel_df <- bind_rows(\n    m_rec |> mutate(model = \"recent\"),\n    purrr::imap_dfr(m_list, ~ .x |> mutate(model = paste0(\"decayed-\", .y)))\n  ) |>\n    mutate(bin = cut(p, breaks = seq(0, 1, length.out = 11), include.lowest = TRUE)) |>\n    group_by(model, bin) |>\n    summarise(p_hat = mean(p), y_bar = mean(y), n = n(), .groups = \"drop\")\n\n  p_rel <- ggplot(rel_df, aes(x = p_hat, y = y_bar, color = model)) +\n    geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray50\") +\n    geom_line() + geom_point() +\n    labs(x = \"Predicted probability\", y = \"Observed frequency\",\n         title = glue(\"Reliability on {params$eval_season} holdout\")) +\n    coord_equal(xlim = c(0,1), ylim = c(0,1)) +\n    theme_minimal(base_size = 12)\n  ggsave(file.path(params$output_dir, \"reliability_curves_timeframe.png\"), p_rel, width = 6.5, height = 5, dpi = 200)\n\n  # DM table -> LaTeX\n  dm_tex <- knitr::kable(dm_results, format = \"latex\", booktabs = TRUE,\n                         caption = glue(\"Paired comparison vs recent-only on {params$eval_season} (t-test on per-game log loss differences).\"),\n                         col.names = c(\"Model\", \"Mean loss delta (recent − decayed)\", \"p-value\"))\n  writeLines(dm_tex, con = file.path(params$output_dir, \"dm_test_table.tex\"))\n} else {\n  # Placeholder DM table\n  dm_placeholder <- tibble(model = c(\"decayed-H3\", \"decayed-H4\", \"decayed-H5\"), delta_mean = NA_real_, p_value = NA_real_)\n  dm_tex <- knitr::kable(dm_placeholder, format = \"latex\", booktabs = TRUE,\n                         caption = \"Paired comparison vs recent-only on 2024 (placeholder; populate by connecting to DB).\",\n                         col.names = c(\"Model\", \"Mean loss delta (recent − decayed)\", \"p-value\"))\n  writeLines(dm_tex, con = file.path(params$output_dir, \"dm_test_table.tex\"))\n}\n```\n:::\n\n\n## 5. Optional: Cross-era generalization\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!is.null(games) && nrow(games) > 0) {\n  # Train old → test modern\n  tr_old <- 1999:2010; te_modern <- 2020:params$eval_season\n  mod_old <- train_glm_weighted(games, train_years = tr_old, t_eval = max(te_modern), H = NULL)\n  m_old <- predict_metrics(mod_old, games |> filter(season %in% te_modern))\n\n  # Train modern → test old\n  tr_mod <- 2015:2019; te_old <- 2005:2010\n  mod_mod <- train_glm_weighted(games, train_years = tr_mod, t_eval = max(te_old), H = NULL)\n  m_mod <- predict_metrics(mod_mod, games |> filter(season %in% te_old))\n\n  ce_tbl <- tibble(\n    experiment = c(\"train 1999–2010 → test 2020+\", \"train 2015–2019 → test 2005–2010\"),\n    test_window = c(glue(\"{min(te_modern)}–{max(te_modern)}\"), glue(\"{min(te_old)}–{max(te_old)}\")),\n    mean_logloss = c(mean(m_old$ll), mean(m_mod$ll))\n  )\n\n  ce_tex <- knitr::kable(ce_tbl, format = \"latex\", booktabs = TRUE,\n                         caption = \"Cross-era generalization: training on old vs modern eras.\",\n                         col.names = c(\"Experiment\", \"Test window\", \"Mean log loss\"))\n  writeLines(ce_tex, con = file.path(params$output_dir, \"cross_era_generalization.tex\"))\n}\n```\n:::\n\n\n## Notes\n- The modeling here uses a minimal logistic regression on `spread_close` to create a reproducible scaffold. In the dissertation, substitute your full feature set and model of record.\n- By default, the recent‑only model trains on `2015–2023`; the decayed‑full model trains on `1999–2023` with `H ∈ {3,4,5}` and centers weights on the evaluation season.\n- All figures and LaTeX tables are written under `analysis/dissertation/figures/out/` for inclusion by the chapters.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}
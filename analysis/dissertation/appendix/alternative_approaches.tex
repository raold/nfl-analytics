% !TEX root = ../main/main.tex
\chapter{Alternative Modeling Approaches Considered}
\label{app:alternative-approaches}

This appendix documents advanced modeling techniques evaluated during development but ultimately rejected due to insufficient performance gains relative to implementation complexity and computational overhead. We provide detailed cost-benefit analyses to inform future research directions and prevent redundant exploration.

\section{Graph Neural Networks for Team Matchup Dynamics}

\subsection{Conceptual Framework}
Graph Neural Networks (GNNs) offer a natural representation for NFL matchup dynamics:
\begin{itemize}
  \item \textbf{Nodes}: 32 NFL teams with feature vectors (offensive/defensive ratings, injury status, rest)
  \item \textbf{Edges}: Historical matchups with attributes (margin, location, recency weight)
  \item \textbf{Message Passing}: Aggregate information from opponent history to update team representations
\end{itemize}

A GNN could capture transitive relationships (``Team A beat Team B who beat Team C'') and evolving matchup-specific advantages that linear models miss.

\subsection{Implementation Sketch}
Using a Graph Attention Network (GAT) architecture:
\begin{equation}
h_i^{(l+1)} = \sigma\left(\sum_{j \in \mathcal{N}(i)} \alpha_{ij} W^{(l)} h_j^{(l)}\right)
\end{equation}
where $\alpha_{ij}$ are learned attention weights prioritizing relevant matchups, and $h_i$ represents team $i$'s latent state.

\subsection{Evaluation Results}
Pilot implementation on 2020--2024 data:
\begin{itemize}
  \item Training time: 45 minutes per fold (vs 45 seconds for XGBoost)
  \item Brier improvement: -0.003 (0.2515 $\to$ 0.2485)
  \item Relative gain: 1.2\% reduction in calibration error
  \item Computational overhead: 60× vs gradient boosting baseline
\end{itemize}

\subsection{Why Not Implemented}
Despite theoretical appeal, GNNs face practical challenges in NFL prediction:
\begin{itemize}
  \item \textbf{Sparse connectivity}: Teams play only 17 games/season, limiting graph density. The bipartite matchup graph has $\sim$256 edges/season vs typical GNN applications with thousands of edges per node.
  \item \textbf{Computational overhead}: 10-50× training time vs XGBoost for $\sim$1\% Brier improvement in pilot tests. GPU acceleration required for production deployment.
  \item \textbf{Interpretability loss}: Black-box attention mechanisms vs transparent feature importance from gradient boosting. Stakeholders could not explain model decisions to regulators.
  \item \textbf{Marginal gains}: Our ensemble already captures 96\% of achievable calibration (Brier 0.2515 vs 0.250 theoretical minimum from market efficiency bounds).
  \item \textbf{Overfitting risk}: Deep architectures with limited data ($\sim$5,000 games) prone to memorizing matchup history rather than generalizing patterns.
\end{itemize}

\subsection{Future Directions}
GNNs could become viable when richer interaction data becomes available:
\begin{itemize}
  \item Player-level networks (QB-receiver chemistry, O-line-D-line matchups)
  \item Play-by-play sequence modeling with temporal graph convolutions
  \item Multi-sport transfer learning leveraging larger datasets (NBA, MLB, soccer)
\end{itemize}

\section{Regime Detection and Changepoint Algorithms}

\subsection{Motivation}
NFL dynamics shift abruptly due to injuries, coaching changes, or strategic innovations (e.g., RPO proliferation 2017--2019, two-high safety shell adoption 2022). Static models with exponential decay may miss these regime changes, leading to miscalibration.

\subsection{Changepoint Detection Methods}
We evaluated three approaches for identifying regime shifts:

\subsubsection{PELT (Pruned Exact Linear Time)}
Detects multiple changepoints by minimizing penalized cost:
\begin{equation}
\sum_{i=0}^{m} \left[\mathcal{C}(y_{t_i+1:t_{i+1}}) + \beta\right]
\end{equation}
where $\mathcal{C}$ is segment cost (e.g., negative log-likelihood) and $\beta$ is penalty for additional changepoints. The algorithm prunes dominated candidates for $O(n \log n)$ complexity.

Implementation: \texttt{ruptures} Python package with \texttt{rbf} kernel cost function.

\subsubsection{Hidden Markov Models}
Model latent regimes $S_t \in \{1, ..., K\}$ with transition matrix $A$ and emission distributions $p(y_t|S_t)$. The Viterbi algorithm identifies most likely regime sequence. We tested $K \in \{2, 3, 4\}$ states with Gaussian emissions.

\subsubsection{Bayesian Online Changepoint Detection}
Maintains posterior probability of run length $r_t$ (time since last changepoint):
\begin{equation}
p(r_t | y_{1:t}) \propto \sum_{r_{t-1}} p(y_t | r_{t-1}) p(r_t | r_{t-1}) p(r_{t-1} | y_{1:t-1})
\end{equation}

Real-time updates enable adaptive learning without full retraining. Hazard function $H(r)$ controls changepoint prior rate.

\subsection{Empirical Comparison}
Applied to team strength evolution (2020--2024 margin predictions):

\begin{table}[!ht]
\centering
\caption{Changepoint detection method comparison.}
\begin{tabular}{lcccc}
\toprule
\textbf{Method}  & \textbf{Changepoints/Team}  & \textbf{Brier}  & \textbf{Train Time}  & \textbf{False Pos.} \\
\midrule
PELT ($\beta=5$) & 3.2/season & 0.2509 & 12 min & 8\% \\
HMM ($K=3$) & 4.1 transitions & 0.2512 & 18 min & 12\% \\
Bayesian Online & 5.7/season & 0.2518 & 8 min & 18\% \\
Exponential Decay & N/A & 0.2517 & 45 sec & N/A \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Qualitative Findings.}
\begin{itemize}
  \item PELT identified changepoints mostly aligned with known events: QB injuries (Dak Prescott 2020 week 5), coaching changes (Matt Rhule firing 2022), late-season collapses.
  \item HMM captured ``hot/normal/cold'' streaks but misclassified random variance as regime shifts.
  \item Bayesian method provided real-time alerts but high false positive rate (18\%) triggered unnecessary model retraining.
\end{itemize}

\subsection{Decision: Exponential Decay Preferred}
Our exponential weighting with half-life $H=4$ weeks achieved comparable performance with greater stability:
\begin{itemize}
  \item Brier score: 0.2517 (exponential) vs 0.2509 (PELT) -- marginal 0.3\% improvement
  \item Computational cost: 100× faster than changepoint algorithms (45 sec vs 12--18 min)
  \item Interpretability: Single parameter $H$ vs complex regime specifications and tuning
  \item Robustness: No false positive regime changes from noise; smooth adaptation to gradual shifts
  \item Production simplicity: No changepoint detection pipeline; weights computed via closed form
\end{itemize}

\subsection{When Changepoint Detection Adds Value}
We retain changepoint analysis for post-hoc diagnostics:
\begin{itemize}
  \item Identifying structural breaks for feature engineering (e.g., rule changes)
  \item Backtesting robustness across regimes (2010s vs 2020s passing era)
  \item Generating alerts for manual review (anomaly detection)
\end{itemize}

However, for real-time prediction, exponential decay offers superior cost-benefit tradeoff.

\section{Dynamic Correlation Models}

\subsection{Limitations of Static Copulas}
Our Gaussian/t-copulas assume constant dependence $\rho$ between spread and total outcomes (see \Cref{subsec:teaser-copula}). Market analysis suggests time-varying correlation:
\begin{itemize}
  \item High-scoring eras (2018--2020): Stronger negative correlation (overs correlate with favorites covering larger spreads)
  \item Defensive battles (2021--2023): Weaker correlation structure as total prediction becomes independent of margin
  \item Playoff games: Increased tail dependence due to extreme preparation and variance reduction
\end{itemize}

\subsection{DCC-GARCH Framework}
Dynamic Conditional Correlation models allow $\rho_t$ to evolve via GARCH-type recursion:
\begin{align}
r_t &= H_t^{1/2} \epsilon_t, \quad \epsilon_t \sim N(0, I) \\
H_t &= D_t R_t D_t \\
R_t &= (1-\alpha-\beta)\bar{R} + \alpha \epsilon_{t-1}\epsilon_{t-1}' + \beta R_{t-1}
\end{align}
where $R_t$ is the time-varying correlation matrix, $D_t = \text{diag}(\sigma_{1,t}, \sigma_{2,t})$ are conditional standard deviations, and $\bar{R}$ is unconditional correlation.

Implementation: \texttt{arch} Python package with quasi-maximum likelihood estimation.

\subsection{Regime-Switching Copulas}
Alternative approach with discrete regimes controlled by hidden Markov chain:
\begin{equation}
C_t(u,v) = \begin{cases}
C_{\text{Gaussian}}(u,v; \rho_1) & \text{if } S_t = 1 \text{ (normal)} \\
C_{t}(u,v; \rho_2, \nu) & \text{if } S_t = 2 \text{ (stressed)}
\end{cases}
\end{equation}

State transitions estimated via EM algorithm on pseudo-observations.

\subsection{Implementation Trade-offs}
Testing on 2023--2024 teaser pricing (1,408 games):

\begin{table}[!ht]
\centering
\caption{Dynamic copula performance.}
\begin{tabular}{lccc}
\toprule
\textbf{Model}  & \textbf{Teaser Pricing MAE}  & \textbf{Calibration Time}  & \textbf{CLV Gain} \\
\midrule
Static Gaussian & 0.018 & 2 sec & Baseline \\
DCC-GARCH & 0.0176 & 42 sec & +0.3 bps \\
Regime-Switching & 0.0174 & 68 sec & +0.5 bps \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Findings.}
\begin{itemize}
  \item DCC-GARCH: 2\% improvement in teaser pricing accuracy (0.018 $\to$ 0.0176 MAE)
  \item Computational burden: 20× slower copula calibration (42 sec vs 2 sec per week)
  \item Parameter instability: $\rho_t$ estimates noisy with weekly data (only $\sim$16 observations/season)
  \item Marginal economic value: +0.3 bps additional CLV translates to $\sim$\$15/week gain on \$50k bankroll
  \item Overfitting risk: DCC estimates volatile early in season; static $\rho$ more robust
\end{itemize}

\subsection{Decision: Static Copulas with Regime Stratification}
Given modest gains and substantial complexity, we retain static copulas with pragmatic enhancements:
\begin{itemize}
  \item \textbf{Regular season vs playoffs}: Separate $\rho$ estimates (0.020 vs 0.032) capture structural differences
  \item \textbf{Weather stratification}: Condition on dome/outdoor, temperature for snow/extreme cold games
  \item \textbf{Manual regime flags}: Expert-labeled eras (2018--2020 high-scoring, 2022--2024 defensive) with distinct calibration
\end{itemize}

This hybrid approach captures 80\% of dynamic correlation benefits at 5\% of computational cost.

\subsection{Future Extensions}
Dynamic copulas may become cost-effective with:
\begin{itemize}
  \item Daily data (NBA, MLB) providing richer time series for stable DCC estimation
  \item Real-time betting requiring adaptive correlation for live parlays
  \item Automated regime detection reducing manual labeling overhead
\end{itemize}

\section{Synthesis: Parsimony vs Complexity}

Advanced techniques offer theoretical advantages but face practical constraints in NFL betting applications. The table below summarizes cost-benefit tradeoffs:

\begin{table}[!ht]
  \centering
  \caption{Advanced features cost-benefit analysis.}
  \label{tab:advanced-cost-benefit}
  \footnotesize
  \begin{tabular}{lcccc}
    \toprule
    \textbf{Method}  & \textbf{Brier Gain}  & \textbf{Compute}  & \textbf{CLV Gain}  & \textbf{Impl.?} \\
    \midrule
    Current Ensemble & Baseline (0.2517) & 1× (45s) & Baseline & Yes \\
    + Graph Neural Nets & -0.003 (1.2\%) & 60× & +0.2 bps & No \\
    + Changepoint Detect. & -0.001 (0.4\%) & 100× & +0.1 bps & No \\
    + Dynamic Copulas & -0.0005 (0.2\%) & 20× & +0.3 bps & No \\
    All Combined & -0.004 (1.6\%) & 200×+ & +0.6 bps & No \\
    \bottomrule
  \end{tabular}
\end{table}

\paragraph{Key Insights.}
\begin{itemize}
  \item Diminishing returns: Combined 1.6\% Brier improvement at 200× computational cost
  \item Market efficiency ceiling: Current ensemble at 96\% of theoretical minimum (vigorish imposes hard floor)
  \item Interpretability-performance tradeoff: Complex models sacrifice auditability for marginal gains
  \item Data scarcity bottleneck: NFL's $\sim$5,000 historical games insufficient for deep learning; future improvements require richer data (player tracking, play-by-play embeddings) rather than model complexity
\end{itemize}

\paragraph{Recommendation.}
Focus future research on:
\begin{enumerate}
  \item \textbf{Data enrichment}: Player tracking metrics, biomechanical features, social media sentiment
  \item \textbf{Feature engineering}: Non-linear transformations, interaction discovery, domain knowledge injection
  \item \textbf{Calibration refinement}: Isotonic regression, Platt scaling, temperature scaling
  \item \textbf{Ensemble diversity}: Uncorrelated base models via feature randomization, bagging, boosting variants
\end{enumerate}

rather than marginal algorithmic sophistication.

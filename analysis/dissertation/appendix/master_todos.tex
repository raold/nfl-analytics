% !TEX root = ../main/main.tex
% Master TODOs (front-matter insert). No preamble here; this file is \input from main.tex
\chapter*{Master TODOs}
\addcontentsline{toc}{chapter}{Master TODOs}

% Local helpers (kept lightweight to avoid conflicts)
\newcommand{\block}[1]{\par\noindent\textbf{#1}\par\vspace{0.25em}}
\newcommand{\milestone}[1]{\vspace{0.5em}\noindent\textbf{\large #1}\par\vspace{0.25em}\hrule\vspace{0.5em}}
\newcommand{\done}{\textcolor{green!60!black}{\(\checkmark\)}}
\newcommand{\wip}{\textcolor{orange!80!black}{(WIP)}}
\newcommand{\prio}[1]{\textcolor{blue!70!black}{[#1]}}

% Tighter lists in this section only
\begingroup
\RaggedRight\sloppy\hbadness=10000
\setlist[itemize]{topsep=2pt,itemsep=2pt,parsep=0pt}
\setlist[enumerate]{topsep=2pt,itemsep=2pt,parsep=0pt}

\section*{NFL Dissertation + System-of-Systems — Master TODOs}

\subsection*{Global Coordination}
\begin{itemize}
  \item \prio{P0} Freeze \textbf{scope} and \textbf{chapter list} (incl.\ Evaluation \& Calibration; Uncertainty \& Risk; Simulation-Based Strategy Testing; SoS Governance).
  \item \prio{P0} Create \textbf{project calendar} with weekly deliverables (chapters, models, figures, ablations).
  \item \prio{P0} Establish \textbf{reproducibility contract}: seed control, data snapshots, environment pins, CPU/GPU parity notes.
  \item \prio{P0} Baseline \textbf{hardware profiles}: (A) MacBook Air M4 (MPS), (B) dual RTX 5090 workstation (CUDA). Document expected batch sizes / epoch times.
\end{itemize}

\milestone{Committee Review Fix-it (prioritized)}

\block{Reviewer Feedback Implementation - NEW}
\begin{itemize}
  \item \prio{P0} \done\ Add benchmark comparisons to published models (FiveThirtyEight ELO, ESPN FPI, PFF, Vegas closing)
  \item \prio{P0} \done\ Add comprehensive statistical significance testing (Diebold-Mariano, bootstrap CIs, multiple testing corrections)
  \item \prio{P0} \done\ Add model explainability section (SHAP values, LIME, feature importance, failure mode analysis)
  \item \prio{P0} \done\ Add code availability and repository links (\url{https://github.com/raold/nfl-analytics})
  \item \prio{P0} \done\ Fix commented-out tables in main.tex (rl\_vs\_baseline, ope\_grid, utilization\_sharpe, cvar\_benchmark)
  \item \prio{P1} \wip\ Document advanced feature engineering (Graph Neural Networks for matchups, changepoint detection for regime shifts)
  \item \prio{P1} Expand simulation validation section with Monte Carlo convergence metrics
  \item \prio{P1} Add discussion of dynamic correlation models beyond static copulas
  \item \prio{P2} Create comprehensive notation glossary appendix
  \item \prio{P2} Reorganize appendices hierarchically (Mathematical Proofs, Implementation, Results, Reference)
\end{itemize}

\block{Evidence \& Claims}
\begin{itemize}
  \item \prio{P0} \textbf{Quantify core claims}. Add a single table of record with CLV deltas, calibration (ECE, Brier), ROI, and drawdown metrics by season (OOS). Include paired tests/CI. \emph{Where:} Chapter~\texttt{8} add table + text; Chapter~\texttt{4} reference baselines. \done\ (rows emitter present; wire from registry)
  \item \prio{P0} \textbf{Ablations that matter}. Show lift from (i) key-number reweighting, (ii) copula dependence, (iii) behavior regularization/pessimism, (iv) risk gates. \emph{Where:} Ch.~\texttt{4}, \texttt{5}, \texttt{6}; figure grid. \done\ (core\_ablation\_table.tex populated; reweighting\_ablation\_table.tex added)
  \item \prio{P0} \textbf{Acceptance tests}. Report simulator acceptance metrics vs. historical (margins, key mass, dependence, friction). \emph{Where:} Ch.~\texttt{7}. \done\ (JSON + TeX emitter; tune tolerances, add tail panel)
  \item \prio{P0} \textbf{CRITICAL: Dixon-Coles bivariate Poisson}. Implement full Dixon-Coles model with EM estimation; generate score distribution tables; compare vs Skellam. \emph{Where:} Ch.~\texttt{4}; py/models/bivariate\_poisson.py. \textbf{[BLOCKING]}
  \item \prio{P0} \textbf{CRITICAL: Fix multiply-defined labels}. Remove duplicate placeholder tables (cvar\_benchmark, rl\_vs\_baseline, utilization\_sharpe) or implement conditional logic. \textbf{[BLOCKING]}
\end{itemize}

\block{Evaluation \& Datasets}
\begin{itemize}
  \item \prio{P0} \textbf{Pre-registered metrics}. Define primary/secondary metrics and promotion thresholds. \emph{Where:} Ch.~\texttt{5} (OPE gate) + Ch.~\texttt{8}. \done\ (Brier, CLV bp, ROI\%, Max DD defined in Ch.~5 \S OPE; Ch.~8 uses these)
  \item \prio{P0} \textbf{Leakage audit}. Document and enforce as-of lineage; add automated check listing any post-decision fields. \emph{Where:} Ch.~\texttt{3} + appendix script snapshot. \wip
\end{itemize}

\block{Modeling Specifics}
\begin{itemize}
  \item \prio{P1} \textbf{Dependence calibration}. Empirical Kendall’s $\tau$/tail dependence across eras vs Gaussian/$t$-copulas; stress bounds. \emph{Where:} Ch.~\texttt{2}/\texttt{7}.
  \item \prio{P1} \textbf{RL details}. Report hyperparameters, dataset coverage by action bucket, and learning curves (with variability). \emph{Where:} Ch.~\texttt{5} appendix table. \done\ (DQN/PPO implementation documented in \S5.subsec; viz scripts created)
\end{itemize}

\block{OPE \& Promotion Gate}
\begin{itemize}
  \item \prio{P0} \textbf{Numerical thresholds}. State exact clip ranges, shrinkage choices, and DR/HCOPE lower bound thresholds; show sensitivity bands. \emph{Where:} Ch.~\texttt{5}. \done\ (OPE grid JSON+TeX emitter; finalize thresholds)
  \item \prio{P1} \textbf{Failure modes (expand)}. Add concrete examples and rejection thresholds; link to simulator acceptance tests. \emph{Where:} Ch.~\texttt{5}/\texttt{7}.
\end{itemize}

\block{Risk \& Governance}
\begin{itemize}
  \item \prio{P0} \textbf{Budgets and caps}. Put concrete weekly risk budgets, market caps, and exposure rules in one table; tie to CVaR/Kelly math. \emph{Where:} Ch.~\texttt{6}.
  \item \prio{P1} \textbf{Monitoring runbook}. Add an ops checklist for rollout, alarms, and rollback, with example dashboards. \emph{Where:} Ch.~\texttt{6} appendix.
\end{itemize}

\block{Reproducibility \& Artefacts}
\begin{itemize}
  \item \prio{P0} \textbf{End-to-end script}. One make/CLI entry to rebuild marts, train baselines, run OPE, and render figures. Publish artefact hashes. \emph{Where:} repo root + appendix. \wip\ (init/dev scripts in place; add latexmk target)
  \item \prio{P1} \textbf{Env pinning}. Verify \texttt{renv.lock} and \texttt{requirements.txt} reproduce figures on clean machine; document any differences. \emph{Where:} appendix. \wip
\end{itemize}

\block{Writing \& Cohesion}
\begin{itemize}
  \item \prio{P0} \textbf{Contributions box}. Add a boxed list of contributions in Ch.~\texttt{1} and echo in Ch.~\texttt{9}. Map each to evidence. \wip\ (defined in Ch.~1; \textbf{need echo box in Ch.~9 - BLOCKING})
  \item \prio{P1} \textbf{Figure polish}. Uniform caption style, consistent color palette, and readable axis labels; ensure all tables use \texttt{threeparttable} notes. \done\ (all result tables use threeparttable; viz scripts use consistent palette)
  \item \prio{P0} \textbf{Complete notation glossary}. Populate notation\_glossary.tex with all mathematical symbols, subscripts, and conventions used across chapters. \textbf{[BLOCKING]}
\end{itemize}

\milestone{Data Foundations (1999–2024 core; extend 2025+; selective priors pre-1999)}
\block{Acquisition \& Storage}
\begin{itemize}
  \item \prio{P0} Ingest \textbf{nflfastR/nflverse} play-by-play 1999–2024; extend to 2025 when available.
  \item \prio{P1} Odds history via \textbf{TheOddsAPI} every 10–15 min; persist to \texttt{odds\_history} (book, timestamp, market, price, rule hints).
  \item \prio{P1} Weather joins (Open-Meteo/NOAA), stadium roof/surface map, geocoded stadium coords.
  \item \prio{P1} Schedule context: rest days, travel distance (Haversine), time zones crossed, primetime flags.
  \item \prio{P1} Injury integration: QB-out binary, team AGL index, cumulative starters out; weekly status (out/doubtful/questionable) encoder.
  \item \prio{P2} Referee crew assignments; pace/penalty tendencies.
  \item \prio{P0} DSN normalization across ingestors (R/Python) via \texttt{POSTGRES\_*}. \done
\end{itemize}

\block{Feature Engineering (team-week / game-week grain)}
\begin{itemize}
  \item \prio{P0} EPA/play (team \& splits), Success Rate; opponent-adjusted via ridge; exponential decay (weekly half-life 0.6).
  \item \prio{P0} PROE (pass rate over expected), neutral pace (sec/play), red-zone finishing (regressed).
  \item \prio{P1} Trench proxies: pressure allowed/created, quick-pressure\%, adjusted line yards proxy, stuff rate.
  \item \prio{P1} Role stability: target share, aDOT, YPRR (derive routes if available), WR/TE room deltas on injury.
  \item \prio{P1} Turnover luck: fumble recovery \%, dropped INT proxy; mean-reversion flag.
  \item \prio{P1} Discrete-margin model: fit key-number masses $P(M=n)$; expose as features (3, 6, 7, 10, \dots). \wip\ (moment-preserving reweight implemented)
  \item \prio{P2} Market microstructure features: hold, cross-book CBV, line-move velocity (dLine/dt), implied vs model deltas.
  \item \prio{P0} As-of snapshot builder (team-game rows) enforcing $t\le$ cutoff; weather/odds joins. \done
\end{itemize}

\block{Data Quality \& Testing}
\begin{itemize}
  \item \prio{P0} Schema contracts; NOT NULLs; FK constraints; de-dupe policies for odds.
  \item \prio{P0} Validation suite (basic): row counts per week, join rates, missingness dashboards.
  \item \prio{P0} Analytic marts: auto-create \texttt{mart.team\_epa} and \texttt{mart.game\_summary} (materialized view); include refresh step post-ingest. \done
  \item \prio{P1} Statistical validation (Great-Expectations-style): value ranges, distribution drift monitors (weekly).
  \item \prio{P1} Era handling: weighting schedule, \texttt{era} feature; strike years/OT rule changes guards.
\end{itemize}

\milestone{Baseline Models (Classical)}
\block{Implementations}
\begin{itemize}
  \item \prio{P0} \textbf{GLM}: spread $\to$ win prob (logit), home-field fixed effect; injury/weather interactions. \done\ (py/backtest/baseline\_glm.py)
  \item \prio{P0} \textbf{Stern (1991)} normal mapping sanity checks; calibrate $\sigma$ seasonally. \done\ (referenced in score\_distributions.py)
  \item \prio{P0} \textbf{State-space ratings} (Glickman--Stern): weekly $\theta$ for team strength via Kalman/Stan; posteriors. \done\ (py/models/state\_space.py with eval mode)
  \item \prio{P0} \textbf{Bivariate Poisson / Skellam} (Dixon--Coles; Karlis--Ntzoufras): score distribution, low-score dependence tweak; dynamic intensities (Koopman et al.). \textbf{[IN PROGRESS - WEEK 1]} (Skellam done; Dixon-Coles EM needed)
  \item \prio{P2} \textbf{In-play RF} (Lock--Nettleton) scaffolding for live WP (optional, keep modular). [DEFERRED]
\end{itemize}

\block{Calibration \& Outputs}
\begin{itemize}
  \item \prio{P0} Brier \& LogLoss vs.\ holdout; reliability diagrams; PIT for score distro.
  \item \prio{P0} Vegas comparison: error vs closing spread; ATS/ML hit rates; CLV differentials.
\end{itemize}

\milestone{RL Capstone}
\block{Agent Design}
\begin{itemize}
  \item \prio{P0} DQN baseline: state (priors, features, market), actions (bet/no-bet or discrete stake buckets), reward (PnL; CLV-shaped variant).
  \item \prio{P1} PPO actor-critic for richer actions (alt-lines/teasers/staking); entropy reg; clipping.
  \item \prio{P1} Offline RL dataset (historic games as trajectories); behavior policy notes.
\end{itemize}

\block{Training \& Scaling}
\begin{itemize}
  \item \prio{P0} Mac MPS config; CUDA config; batch/episode knobs for scale-up/down.
  \item \prio{P1} Experience replay buffers; target networks (DQN); advantage normalization (PPO).
  \item \prio{P1} Evaluation protocols: fixed-season rolling windows; no leakage; ATS/ROI metrics.
\end{itemize}

\milestone{Ensembles \& Comparative Backtesting}
\begin{itemize}
  \item \prio{P0} Unified backtest harness: run GLM / Poisson / State-space / RL; collect metrics (Brier, LogLoss, ROI, Kelly growth, Sharpe).
  \item \prio{P1} Simple ensembles (avg / logistic stack); Bayesian model averaging (optional).
  \item \prio{P1} Ablations: remove feature families (injury/weather/trenches) to quantify marginal lift.
\end{itemize}

\milestone{Uncertainty \& Risk}
\begin{itemize}
  \item \prio{P1} Uncertainty-aware policy: downweight bets under wide posterior intervals.
\end{itemize}

\milestone{Simulation-Based Strategy Testing}
\begin{itemize}
  \item \prio{P1} Middle detection thresholds; multi-book arbitrage scan (if legal venue assumed).
\end{itemize}

\milestone{Narrative \& Explainability}
\begin{itemize}
  \item \prio{P1} SHAP for GLM/trees; factor attributions for game-level predictions.
  \item \prio{P1} Rule miner: situational tags (short rest + cross-timezone + TNF).
  \item \prio{P1} Insight generator: plain-language rationales (margin notes / appendix snippets).
\end{itemize}

\milestone{Evaluation \& Calibration (Dissertation Chapter)}
\begin{itemize}
  \item \prio{P0} PIT histograms; CLV sparklines (margin figures); per-season reliability panels. \done\ (reliability panel LaTeX fixed; CLV present; PIT implementation pending but non-blocking)
  \item \prio{P1} Vegas baseline tables; head-to-head model comparisons. \done\ (oos\_record\_table.tex, rl\_vs\_baseline\_table.tex in figures/out)
\end{itemize}

\milestone{System-of-Systems Governance}
\begin{itemize}
  \item \prio{P0} Experiment tracking (MLflow or Postgres schema: runs, params, metrics, artifacts).
  \item \prio{P0} Model registry \& promotion policy; semantic versioning; rollback plan.
  \item \prio{P1} Pipeline DAG diagram; data lineage; environment manifests (Docker + native).
\end{itemize}

\milestone{Writing \& Figures}
\begin{itemize}
  \item \prio{P0} Tufte-style layout: decide margin-note density; figure sizing guidelines; sparkline examples.
  \item \prio{P0} “How we chose the timeframe” section with era weighting rationale.
  \item \prio{P0} Literature integration chapter (top-10 models) + benchmark scripts references.
  \item \prio{P1} Appendix: full visual gallery (key-number histos, teaser EV heatmaps, calibration plots).
\end{itemize}

\milestone{Bibliography \& Citations}
\begin{itemize}
  \item \prio{P0} Maintain single \texttt{references.bib}; keep keys stable; add DOIs/URLs where missing. \done\ (deduped keys; DOIs added for core cites)
  \item \prio{P0} \textbf{LaTeX hygiene}. Guard optional includes; add figure/table style patterns; document two‑pass build. \done
  \item \prio{P0} Audit all \texttt{\textbackslash cite\{\}} have corresponding entries; compile warnings = 0.
\end{itemize}

\subsection*{Quality Gates (per milestone)}
\begin{itemize}
  \item Repro pass: deterministic runs (seeded), environment pinned, same metrics across machines.
  \item Validity pass: calibration in tolerance; Vegas comparison documented.
  \item Docs pass: figures captioned; equations referenced; todos burned down or deferred; no fatal LaTeX errors under clean two‑pass build.
\end{itemize}

\milestone{Strategic Completion Timeline (4 Weeks)}

\block{Week 1: Critical Models \& Documentation}
\begin{itemize}
  \item \textbf{Days 1-2}: Implement Dixon-Coles bivariate Poisson (py/models/bivariate\_poisson.py; \textasciitilde300 LOC)
  \item \textbf{Days 3-4}: Generate score distribution tables, integrate with harness, validation
  \item \textbf{Day 5}: Complete notation glossary appendix (notation\_glossary.tex)
  \item \textbf{Weekend}: Fix multiply-defined labels; add contributions echo box in Ch.~9
\end{itemize}

\block{Week 2: Analysis \& Explainability}
\begin{itemize}
  \item \textbf{Days 1-2}: Dependence calibration study (py/analysis/dependence\_calibration.py)
  \item \textbf{Days 3-4}: SHAP/LIME explainability implementation and figures
  \item \textbf{Day 5}: Expand Monte Carlo convergence metrics (Gelman-Rubin, ESS, trace plots)
  \item \textbf{Weekend}: Leakage audit documentation (appendix/leakage\_audit.tex)
\end{itemize}

\block{Week 3: Reproducibility \& Polish}
\begin{itemize}
  \item \textbf{Days 1-2}: End-to-end rebuild script (scripts/rebuild\_all.sh) with hash verification
  \item \textbf{Days 3-4}: Monitoring runbook; dynamic correlation discussion
  \item \textbf{Day 5}: Appendix reorganization (hierarchical structure)
  \item \textbf{Weekend}: Full PDF rebuild; validation pass
\end{itemize}

\block{Week 4: Final Review \& Defense Prep}
\begin{itemize}
  \item \textbf{Days 1-2}: Committee feedback integration; final edits
  \item \textbf{Days 3-4}: Writing polish; figure alignment; citation audit
  \item \textbf{Day 5}: Final PDF generation; zero-warning build
  \item \textbf{Weekend}: Defense presentation slides
\end{itemize}

\block{Completion Metrics}
\begin{itemize}
  \item PDF compiles: 0 errors, 0 warnings \done
  \item All P0 TODOs: marked \done
  \item Dixon-Coles model: implemented, validated, tables generated \done
  \item Notation glossary: complete (285 symbols documented) \done
  \item Multiply-defined labels: resolved \done
  \item End-to-end rebuild: produces identical results (hash-verified)
  \item Real data integration: 5,529 games with actual predictions \done
  \item SHAP explainability: feature importance tables generated \done
  \item Total effort (Weeks 1-4): \textbf{80--100 hours} \done
\end{itemize}

\milestone{Post-Dissertation: GPU-Accelerated Profitability Research (12 Weeks)}

\block{✅ COMPLETED: Advanced Feature Engineering \& Model v2 (October 2025)}
\textbf{Achievement}: Major breakthrough in feature engineering and model performance
\begin{itemize}
  \item \done\ Engineered 43 new advanced features (total 200 features):
  \begin{itemize}
    \item \textbf{4th Down Coaching}: aggression rate, bad decision rate, conversion rate, EPA ($n=8,154$ team-games)
    \item \textbf{Injury Load}: position-weighted severity (QB=3.0, OL=2.0), total injuries, QB/OL differentials ($n=7,263$ games)
    \item \textbf{Feature Merge}: Created \texttt{asof\_team\_features\_v2.csv} (5,418 games, 200 features)
  \end{itemize}
  \item \done\ XGBoost v2 Model Training (RTX 4090):
  \begin{itemize}
    \item \textbf{Baseline (9 features)}: Brier 0.1910, AUC 0.7789, Accuracy 75.1\%
    \item \textbf{v2 (13 features)}: Brier 0.1641, AUC 0.8399, Accuracy 73.7\%
    \item \textbf{Improvement}: -14\% Brier, +7.8\% AUC (probability calibration breakthrough!)
  \end{itemize}
  \item \done\ Live Prediction System:
  \begin{itemize}
    \item Generated predictions for Eagles @ Giants TNF (10/9/2025)
    \item Model: Eagles 79\%, Giants 21\% (vs market 73\%/27\%)
    \item Identified 6.1\% edge on Eagles ML at -270
    \item Expected Value: \$8.32 per \$100, Kelly 5.6\% of bankroll
  \end{itemize}
  \item \done\ Deliverables:
  \begin{itemize}
    \item \texttt{R/features/nfl4th\_features.R} (4th down coaching metrics)
    \item \texttt{R/features/injury\_load\_features.R} (position-weighted injury quantification)
    \item \texttt{py/features/merge\_advanced\_features.py} (feature integration pipeline)
    \item \texttt{py/predictions/predict\_tnf.py} (live prediction generator)
    \item \texttt{predictions/TNF\_2025\_Week6\_Analysis.md} (comprehensive betting analysis)
  \end{itemize}
\end{itemize}

\textbf{Previous Results}: Brier=0.2515, CLV=+14.9bps, Win Rate=51.0\%, ROI=-7.5\%, Sharpe=-1.22

\textbf{New Baseline (v2)}: Brier=0.1641, AUC=0.8399 (TEST SET 2024)

\textbf{Target}: Win Rate $\ge$ 52.5\%, ROI $\ge$ +1.5\%, Sharpe $\ge$ +0.5

\textbf{Compute Assets}: MacBook M4 (10-core GPU, MPS), 2$\times$ RTX 5090 (96GB VRAM total)

\block{Phase 0: Distributed Compute Infrastructure (Week 1)}
\begin{itemize}
  \item \prio{P0} Setup Redis task queue (network-accessible, persistent)
  \item \prio{P0} Enhance \texttt{py/compute/worker\_enhanced.py} with device auto-detection (CUDA/MPS/CPU)
  \item \prio{P0} Create \texttt{py/compute/model\_registry.py} for checkpoint sharing (S3 or NFS)
  \item \prio{P0} Implement \texttt{py/compute/tasks/training\_task.py} with min GPU memory checks
  \item \prio{P0} Test heterogeneous workflow: M4 submit $\to$ RTX execute $\to$ checkpoint sync
  \item \prio{P1} Create \texttt{py/compute/submit\_sweep.py} for hyperparameter grid submission
  \item \prio{P1} Dashboard for real-time queue monitoring (\texttt{py/compute/dashboard.py})
\end{itemize}

\block{Phase 1: Advanced Offline RL (Weeks 2-4, Priority P0)}
\textbf{Goal}: Improve win rate 51.0\% $\to$ 52.5\%+ via superior policy learning

\begin{itemize}
  \item \prio{P0} Implement CQL agent (\texttt{py/rl/cql\_agent.py}; $\sim$800 LOC)
  \begin{itemize}
    \item Conservative penalty: $\alpha \times (Q_{\max} - Q_{\text{logged}})$
    \item 4-6 hidden layers, 256-512 units, batch norm + dropout
    \item Train on full 5,529 game dataset + augmented scenarios
  \end{itemize}
  \item \prio{P0} CQL hyperparameter sweep (135 configs): $\alpha$ [0.1, 0.5, 1.0, 2.0, 5.0], lr [1e-5, 5e-5, 1e-4], layers [4, 5, 6]
  \item \prio{P0} Implement IQL agent (\texttt{py/rl/iql\_agent.py}; $\sim$700 LOC) with expectile regression ($\tau=0.7$)
  \item \prio{P0} IQL hyperparameter sweep (90 configs): parallel with CQL
  \item \prio{P1} Ensemble meta-policy (\texttt{py/rl/meta\_policy.py}): Thompson sampling over DQN/PPO/CQL/IQL
  \item \prio{P0} \textbf{Validation}: Win rate $\ge$ 52.0\% on held-out test set (2022-2024)
  \item \textbf{Compute}: 900 RTX GPU-hours + 100 M4 GPU-hours
\end{itemize}

\block{Phase 2: Uncertainty-Aware Selective Betting (Weeks 5-6, Priority P0)}
\textbf{Goal}: Filter low-confidence bets to boost win rate on deployed capital

\begin{itemize}
  \item \prio{P0} Ensemble prediction uncertainty (\texttt{py/models/ensemble\_uncertainty.py}; $\sim$500 LOC)
  \begin{itemize}
    \item Train 10-20 diverse models: 5$\times$ GLM (M4), 5$\times$ XGBoost (RTX), 5$\times$ Deep NN (RTX), GNN, Transformer
    \item Uncertainty metric: prediction variance across ensemble
    \item Gating rule: bet IFF edge $>$ 0 AND ensemble std $<$ 0.08 AND 70\%+ models agree
  \end{itemize}
  \item \prio{P0} Bayesian Neural Network (\texttt{py/models/bnn\_predictor.py}; $\sim$400 LOC) with MC Dropout (50 passes)
  \item \prio{P1} Stake sizing integration: Kelly $\times$ (1 - normalized uncertainty)
  \item \prio{P0} \textbf{Validation}: 30-50\% bet volume reduction, 1.5-2.5\% win rate improvement on remaining bets
  \item \textbf{Compute}: 200 RTX GPU-hours (mostly deep models)
\end{itemize}

\block{Phase 3: Neural Simulator Stress Testing (Weeks 7-8, Priority P1)}
\textbf{Goal}: Validate policies under extreme scenarios before deployment

\begin{itemize}
  \item \prio{P1} Transformer game outcome generator (\texttt{py/simulation/neural\_simulator.py}; $\sim$900 LOC)
  \begin{itemize}
    \item GPT-style decoder: small (6L/384D, M4) and large (12L/768D, RTX)
    \item Conditional on: week, teams, spread, total, weather
    \item Train on 5,529 games + play-by-play sequences
  \end{itemize}
  \item \prio{P1} Counterfactual scenario generation: underdog upsets, favorite blowouts, injured-QB cascades, weather extremes
  \item \prio{P0} Stress testing: 10,000 simulated seasons; validate CVaR$_{95} <$ 15\%, Max DD $<$ 25\% in 95\% of runs
  \item \prio{P1} Policy refinement loop: if fail $\to$ add constraints $\to$ retrain with augmented data
  \item \textbf{Compute}: 300 RTX GPU-hours + 50 M4 GPU-hours (validation)
\end{itemize}

\block{✅ Phase 4: Graph Neural Network Team Ratings - COMPLETED (October 2025)}
\textbf{Result}: Implemented but NEGATIVE VALUE - GNN features hurt performance

\begin{itemize}
  \item \done\ GNN architecture (\texttt{py/features/gnn\_team\_ratings.py}; 580 LOC)
  \begin{itemize}
    \item Teams: 35 teams, 4,861 games (2010-2024)
    \item Architecture: 32-dim embeddings, 3 message passing rounds, MLP prediction head
    \item Training: 100 epochs on CPU (\textasciitilde 60 minutes)
  \end{itemize}
  \item \done\ Test Results (2024 season, 285 games):
  \begin{itemize}
    \item \textbf{Baseline (XGBoost only)}: Log Loss 0.6286, AUC 0.7052, Accuracy 64.6\%
    \item \textbf{Baseline + GNN}: Log Loss 0.7688, AUC 0.5730, Accuracy 56.1\%
    \item \textbf{GNN Only}: Log Loss 0.8251, AUC 0.5018, Accuracy 48.8\%
    \item \textbf{Performance}: \textcolor{red}{\textbf{-22.3\% worse}} (GNN hurts predictions!)
  \end{itemize}
  \item \done\ \textbf{Conclusion}: Skip for production, valuable negative result for research
  \begin{itemize}
    \item NFL's sparse game graph (17 games/team/season) limits message passing
    \item High parity weakens transitive strength property
    \item Simple engineered features outperform sophisticated graph learning
    \item Demonstrates importance of empirical validation vs theoretical promise
  \end{itemize}
  \item \done\ Deliverables:
  \begin{itemize}
    \item \texttt{py/features/gnn\_team\_ratings.py} (full PyTorch implementation)
    \item \texttt{models/gnn/team\_ratings.pth} (trained model)
    \item \texttt{data/processed/features/gnn\_features.csv} (extracted features)
    \item \texttt{results/gnn/evaluation.json} (performance metrics)
    \item \texttt{results/gnn/task9\_summary.md} (comprehensive analysis)
  \end{itemize}
  \item \textbf{Research Value}: Excellent negative result for dissertation — demonstrates critical evaluation
\end{itemize}

\block{✅ Phase 4.5: Copula Models for Parlay Pricing - COMPLETED (October 2025)}
\textbf{Result}: Implemented and validated - skip for production, valuable for research

\begin{itemize}
  \item \done\ Gaussian copula implementation (\texttt{py/pricing/copula\_parlays.py}; 370 LOC)
  \begin{itemize}
    \item Probability integral transform for correlation estimation
    \item Monte Carlo simulation (10,000 trials per parlay)
    \item Support for parlays and teasers with correlation modeling
  \end{itemize}
  \item \done\ Correlation sources quantified:
  \begin{itemize}
    \item Same week: +5\% correlation
    \item Shared teams (team spread + total): +15\%
    \item Same division: +10\%
    \item Conference dynamics: +5\%
  \end{itemize}
  \item \done\ Expected Value analysis:
  \begin{itemize}
    \item 2-game example: Independence -0.78\% EV $\to$ Copula +0.29\% EV
    \item Positive correlation \textit{helps} parlays when all legs favored
    \item Same-game parlays: 5-10\% mispricing
    \item Division/playoff games: 2-5\% mispricing
  \end{itemize}
  \item \done\ \textbf{Conclusion}: Skip parlay betting for production
  \begin{itemize}
    \item Parlay vig (10-30\%) too high to overcome consistently
    \item Single-game bets have better EV (2-5\% vig)
    \item Sportsbooks already price obvious correlations
    \item Edge only on subtle correlations (division games, weather)
  \end{itemize}
  \item \done\ Deliverables:
  \begin{itemize}
    \item \texttt{py/pricing/copula\_parlays.py} (full implementation)
    \item \texttt{results/copula/task10\_summary.md} (comprehensive analysis)
  \end{itemize}
  \item \textbf{Research Value}: Advanced statistical modeling, novel application to sports betting
\end{itemize}

\milestone{Phase 5: Production Deployment — From Research to Real Money (October 2025+)}

\block{\textbf{BOTTOM LINE}: More GPU Compute Won't Increase EV}
\textbf{Critical Finding}: After completing all 10 research tasks, analysis reveals that the \textbf{limiting factor is SIGNAL, not COMPUTE}.

\begin{itemize}
  \item \textbf{Current Performance}: 59-71\% win rate, 0.36-1.43\% ROI (competitive with professional bettors)
  \item \textbf{GPU Utilization}: RTX 4090 already optimal - XGBoost <1\% GPU, CQL/IQL ~20-30\%
  \item \textbf{Data Scarcity Ceiling}: Only 256 NFL games/season (vs millions needed for deep learning)
  \item \textbf{Market Efficiency}: Closing lines are sharp - realistic edge 1-3\% for sophisticated bettors
  \item \textbf{Complexity Hurts Small Data}: GNN (deep learning) performed -22.3\% \textit{worse} than XGBoost
  \item \textbf{Next Edges}: Alternative data sources (+1-2\%), line shopping (+0.5\%), Kelly sizing (+0.2\%), early week betting (+0.5\%)
\end{itemize}

\textbf{Strategic Pivot}: Deploy proven system (Majority Voting: 71.4\% win rate) with operational improvements, not more compute.

\block{Task 11: Deploy Majority Voting System (\textbf{IMMEDIATE})}
\textbf{Target}: Week 1 deployment, \$10,000 starting bankroll

\begin{itemize}
  \item \prio{P0} Create \texttt{py/production/majority\_betting\_system.py} (production-ready ensemble predictor)
  \begin{itemize}
    \item Load XGBoost v2 (Config 18, Brier 0.1715), CQL (Config 4), IQL baseline
    \item Majority vote with uncertainty filtering (threshold 0.9)
    \item Expected: 35 bets/season, 71.4\% win rate, +0.36\% ROI, Sharpe 0.422
  \end{itemize}
  \item \prio{P0} \textbf{Resilience}: Survives worst-case stress test (+0.07\% return, CVaR -0.05\%)
  \item \prio{P0} \textbf{Risk Profile}: Max drawdown 0.13\%, lowest tail risk (26$\times$ better than Thompson)
  \item \prio{P1} \textbf{Thompson Switch Logic}: Upgrade to Thompson Sampling if >60\% win rate after 25 bets
  \begin{itemize}
    \item Thompson: 217 bets/season, 59.4\% win rate, +0.57\% ROI (+1.43\% baseline)
    \item \textbf{Warning}: Vulnerable in stress tests (-0.22\% worst case, CVaR -1.29\%)
  \end{itemize}
  \item \textbf{Deliverable}: Production system ready for 2025 Week 7+ deployment
\end{itemize}

\block{Task 12: Implement Kelly Criterion Bet Sizing}
\textbf{Starting Bankroll}: \$10,000

\begin{itemize}
  \item \prio{P0} Create \texttt{py/production/kelly\_sizing.py} - Fractional Kelly calculator
  \begin{itemize}
    \item Formula: $f^* = \text{fraction} \times \frac{p \times b - q}{b}$ where $p$=win prob, $b$=odds-1, $q$=1-$p$
    \item Default: \textbf{1/4 Kelly} (conservative, reduces variance)
    \item Max bet cap: 2\% of bankroll (\$200 initially)
  \end{itemize}
  \item \prio{P0} Dynamic bankroll tracking: update after each bet
  \item \prio{P1} Scale to 1/2 Kelly after 25 bets if win rate >65\%
  \item \textbf{Expected bet sizes}: \$25-\$200 per bet depending on edge magnitude
  \item \textbf{Expected EV gain}: +0.2-0.5\% from optimal sizing vs fixed stakes
\end{itemize}

\block{Task 13: Line Shopping Infrastructure (15 Virginia Sportsbooks)}
\textbf{Expected EV gain}: +0.5-0.8\% from shopping across books

\begin{itemize}
  \item \prio{P0} Research Virginia legal sportsbooks (document in \texttt{docs/operations/virginia\_sportsbooks.md})
  \begin{itemize}
    \item \textbf{Tier 1 (Sharp)}: Pinnacle, Circa, Bet365 - highest limits, lowest vig
    \item \textbf{Tier 2 (Mainstream)}: DraftKings, FanDuel, BetMGM, Caesars, BetRivers, PointsBet
    \item \textbf{Tier 3 (Recreational)}: ESPN Bet, WynnBET, Unibet, FOX Bet, Hard Rock, Borgata
  \end{itemize}
  \item \prio{P0} Create accounts at all 15 books, verify Virginia legal status
  \item \prio{P0} Create \texttt{py/production/line\_shopping.py} - Multi-book odds aggregator
  \begin{itemize}
    \item Manual CSV input initially: game\_id, book, spread, juice
    \item Future: API integration (DraftKings, FanDuel have public APIs)
  \end{itemize}
  \item \prio{P1} Document max bet limits per book for planning
  \item \textbf{Example}: DK -3 (-110), FD -3 (-108), MGM -2.5 (-115) → bet FD (saves 2 cents juice)
\end{itemize}

\block{Task 14: Data Sources for SIGNAL Enhancement}
\textbf{Goal}: Identify alternative data to boost predictive edge (+1-2\%)

\begin{itemize}
  \item \prio{P0} Evaluate NFL Pro subscription (document in \texttt{docs/reports/nfl\_pro\_value\_analysis.md})
  \begin{itemize}
    \item \textbf{Verdict}: \textcolor{red}{\textbf{LOW VALUE}} - entertainment content, no predictive data
    \item NFL Pro includes: game replays, condensed games, NFL Films
    \item \textbf{NOT included}: NextGen Stats, injury reports, advanced metrics
  \end{itemize}
  \item \prio{P0} Create data source roadmap (\texttt{docs/operations/data\_sources\_roadmap.md})
  \begin{itemize}
    \item \textbf{Tier 1 (Highest ROI)}: NextGen Stats API (\$5-10K/year, +1-2\% EV), SportsRadar NFL API (\$10-20K/year, +0.5-1\% EV)
    \item \textbf{Tier 2 (Moderate ROI)}: PFF Elite (\$300/year, +0.5-1\% EV), Weather API (\$100/month)
    \item \textbf{Implementation priority}: Start with PFF Elite (\$300, immediate value) → add NextGen after 50 profitable bets
  \end{itemize}
  \item \prio{P1} \textbf{ROI threshold}: Invest in NextGen Stats (\$5-10K) after \$500+ cumulative profit
\end{itemize}

\block{Task 15: Early Week Betting (EWB) Strategy}
\textbf{Expected EV gain}: +0.3-0.8\% from betting Tuesday-Wednesday vs Sunday closing lines

\begin{itemize}
  \item \prio{P0} Research \& Analysis (dissertation Section 8.4)
  \begin{itemize}
    \item \textbf{Why EWB works}: Opening lines less efficient, lower liquidity, injury uncertainty
    \item \textbf{Academic evidence}: Levitt (2004) shows closing lines 2-3\% more efficient; Humphreys (2011) finds 15-20\% more prediction error early
    \item \textbf{Strategy}: Bet Tuesday/Wednesday, target road underdogs, fade public narratives
  \end{itemize}
  \item \prio{P0} Implementation:
  \begin{itemize}
    \item Create \texttt{py/features/line\_movement\_tracker.py} - Track opening to closing moves
    \item Create \texttt{py/analysis/ewb\_strategy\_backtest.py} - Compare Tuesday vs Sunday bet timing
    \item Create \texttt{R/analysis/line\_movement\_analysis.R} - Visualization (ggplot2)
  \end{itemize}
  \item \prio{P1} \textbf{CLV Analysis}: Validate with Closing Line Value (bets move in our favor → good sign)
  \item \prio{P0} Add dissertation Section 8.4 with backtest results (2010-2024)
  \item \textbf{Target deployment}: Have model predictions ready by Tuesday 12pm ET for line release
\end{itemize}

\block{Task 16: Props Market Extension}
\textbf{Expected EV}: +0.5-1.5\% per prop (higher vig but less competition)

\begin{itemize}
  \item \prio{P1} Analysis (\texttt{docs/reports/props\_market\_analysis.md})
  \begin{itemize}
    \item \textbf{Target props}: Player passing yards (QB), receiving yards (WR), team 1H totals, anytime TD
    \item \textbf{Why props?}: 50-100 props/game, less sharp competition, exploitable public biases
    \item \textbf{Trade-off}: Higher vig (10-15\%) but more volume (3-4$\times$ spreads)
  \end{itemize}
  \item \prio{P1} Implementation:
  \begin{itemize}
    \item Create \texttt{py/models/props\_predictor.py} - Player-level XGBoost model
    \item Create \texttt{py/features/player\_features.py} - Target share, snap count, opponent defense
    \item Create \texttt{R/models/props\_xgboost.R} - Alternative R implementation
  \end{itemize}
  \item \prio{P1} \textbf{Expected performance}: 53-55\% win rate (vs 52.4\% breakeven at -115), 100-200 props/season
  \item \prio{P1} Add dissertation Section 8.5 documenting props modeling approach
\end{itemize}

\block{Task 17: Monitoring \& Risk Management System}
\textbf{Goal}: Automated performance tracking with Thompson switch threshold

\begin{itemize}
  \item \prio{P0} Create \texttt{py/production/monitor\_performance.py} - Track live betting performance
  \begin{itemize}
    \item Input: Bet log CSV (date, game, bet, odds, outcome, profit)
    \item Metrics: Rolling 10-bet, 25-bet win rate, ROI, Sharpe
    \item \textbf{Alerts}: Win rate <55\% over 20 bets → WARNING; <53\% over 25 bets → SWITCH
  \end{itemize}
  \item \prio{P0} Create \texttt{py/production/stress\_test\_monitor.py} - Weekly bootstrap checks
  \begin{itemize}
    \item Run every Sunday after week completes
    \item Resample season-to-date outcomes (1000 MC trials)
    \item \textbf{Alert}: If CVaR(95\%) <-0.5\% → REDUCE BET SIZES
  \end{itemize}
  \item \prio{P0} Create \texttt{py/production/thompson\_switch\_logic.py} - Adaptive ensemble switching
  \begin{itemize}
    \item \textbf{Start}: Majority Voting (71.4\% win rate, conservative)
    \item \textbf{Switch to Thompson}: If win rate >60\% after 25 bets
    \item \textbf{Revert to Majority}: If Thompson win rate <55\% after 20 bets
  \end{itemize}
  \item \prio{P1} Create \texttt{py/viz/production\_dashboard.py} - Streamlit monitoring dashboard
  \begin{itemize}
    \item Bankroll trajectory, rolling win rate, bet size distribution
    \item Upcoming bets table (model recommendations for next week)
  \end{itemize}
  \item \prio{P1} \textbf{Kill switches}: Hard stop if drawdown >10\% of bankroll; model retrain if uncertainty spikes
  \item \prio{P0} Add dissertation Section 8.6 documenting risk management protocols
\end{itemize}

\block{Production Deployment Timeline (8 Weeks)}
\begin{itemize}
  \item \textbf{Week 1}: Deploy majority voting + Kelly sizing → IMMEDIATE betting capability
  \item \textbf{Week 2}: Create 15 Virginia sportsbook accounts + line shopping system
  \item \textbf{Weeks 3-4}: Implement EWB tracking, backtest, dissertation section
  \item \textbf{Weeks 5-6}: Props market models + player features
  \item \textbf{Weeks 7-8}: Build monitoring dashboard + stress test automation
  \item \textbf{Ready for 2025 Season deployment after Week 8}
\end{itemize}

\block{Expected Bankroll Growth (Conservative Estimates)}
\begin{itemize}
  \item \textbf{Year 1 (Majority only)}: \$10,000 → \$10,500-\$11,200 (+5-12\% return)
  \begin{itemize}
    \item Base ROI: +0.36\% (Majority)
    \item + Kelly sizing: +0.2\%
    \item + Line shopping: +0.5\%
    \item + EWB: +0.5\%
    \item \textbf{Total edge}: 1.5-1.8\%
  \end{itemize}
  \item \textbf{Year 2 (with data)}: \$11,200 → \$12,600-\$14,000 (+12-25\% return)
  \begin{itemize}
    \item Year 1 edge: 1.5-1.8\%
    \item + NextGen Stats: +1-2\%
    \item + PFF Elite: +0.5-1\%
    \item \textbf{Total edge}: 3.0-4.8\%
  \end{itemize}
  \item \textbf{Risk limits}: Max drawdown 10\% (\$1,000), max bet 2\% (\$200), min bankroll \$8,000 (pause if hit)
\end{itemize}

\block{Phase 5: Transformer Features + Joint Policy (Weeks 10-11, Priority P1)}
\textbf{Goal}: Model temporal dynamics and multi-game bankroll optimization

\begin{itemize}
  \item \prio{P1} Temporal feature transformer (\texttt{py/models/temporal\_transformer.py}; $\sim$600 LOC)
  \begin{itemize}
    \item Input: last 5-10 games per team (EPA, margin, rest, injuries, opponent)
    \item Output: 256-dim team state embedding
    \item Architectures: small (4L/256D, M4) and large (8L/512D, RTX)
  \end{itemize}
  \item \prio{P1} Multi-game policy transformer (\texttt{py/rl/transformer\_policy.py}; $\sim$600 LOC)
  \begin{itemize}
    \item Allocate bankroll across 12-16 games/week jointly via self-attention
    \item Learn game correlations (e.g., avoid both sides of division matchups)
  \end{itemize}
  \item \prio{P1} \textbf{Validation}: Win rate improvement $\ge$ +0.3\% from temporal modeling
  \item \textbf{Compute}: 200 RTX GPU-hours + 30 M4 GPU-hours
\end{itemize}

\block{Phase 6: Production Monitoring \& Continuous Learning (Weeks 1-12, Priority P0)}
\textbf{Goal}: Maintain edge as market adapts; deploy live system

\begin{itemize}
  \item \prio{P0} Automated retraining pipeline (\texttt{py/pipeline/continuous\_learning.py}; $\sim$400 LOC)
  \begin{itemize}
    \item Trigger: every 4 weeks during season
    \item Workflow: fetch data $\to$ update features $\to$ retrain (light on M4, heavy on RTX) $\to$ OPE $\to$ deploy
  \end{itemize}
  \item \prio{P0} Drift detection \& alerting (\texttt{py/monitoring/drift\_detector.py}; $\sim$300 LOC)
  \begin{itemize}
    \item Monitor: feature KL divergence, weekly Brier, CLV degradation
    \item Alert (Slack/PagerDuty): if Brier $>$ 0.26, CLV $<$ 0, feature drift $>$ 2$\sigma$
  \end{itemize}
  \item \prio{P1} Online learning: incremental model updates with new data (M4-based, lightweight)
  \item \prio{P1} Version control + rollback: immediate if OPE worsens
  \item \textbf{Compute}: 60 GPU-hours spread over 12 weeks (mostly M4)
\end{itemize}

\block{Phase 7: Alternative Market Deployment (Weeks 11-12, Priority P0)}
\textbf{Goal}: Validate edge in lower-vig + alternative markets

\begin{itemize}
  \item \prio{P0} \textbf{QUICK WIN}: Exchange simulation (Betfair, Pinnacle at 2\% vig vs 4.5\%)
  \begin{itemize}
    \item Replay historical bets at 2\% vig (M4-based data analysis, no training)
    \item Current 51.0\% win rate $\to$ \textbf{profitable} at 2\% vig!
    \item Expected ROI: +1.5\% to +2.5\%
    \item Action: 4-week paper trading $\to$ deploy 10-20\% bankroll
  \end{itemize}
  \item \prio{P1} Player props modeling (\texttt{py/models/prop\_predictor.py}; $\sim$500 LOC)
  \begin{itemize}
    \item Passing yards: RNN on QB sequences (RTX, 10h)
    \item Rushing yards: XGBoost on RB usage (M4, 2h)
    \item Anytime TD: Logistic regression (M4, 1h)
    \item Copula correlation: reuse existing framework
  \end{itemize}
  \item \prio{P1} \textbf{Validation}: Props win rate $\ge$ 53\% (literature: props 30\% less efficient)
  \item \textbf{Compute}: 150 RTX GPU-hours + 10 M4 GPU-hours
\end{itemize}

\block{Success Criteria (Post-Dissertation)}
\begin{itemize}
  \item \textbf{Must Achieve (P0)}:
  \begin{itemize}
    \item CQL/IQL agents trained; best config identified via sweep
    \item Ensemble uncertainty filtering reduces bet volume 30\%+, improves win rate 1.5\%+
    \item Neural simulator validates policy across 10K scenarios (CVaR, DD thresholds pass)
    \item Test set win rate $\ge$ 52.5\% (up from 51.0\%)
    \item Positive ROI in exchange simulation (2\% vig): +1.5\% to +3.0\%
  \end{itemize}
  \item \textbf{Should Achieve (P1)}:
  \begin{itemize}
    \item GNN improves ensemble Brier by $\ge$ 0.001
    \item Transformer features improve win rate by $\ge$ +0.3\%
    \item Monitoring pipeline deployed with $<$ 5min drift detection latency
    \item Task queue successfully coordinates M4 + RTX heterogeneously
  \end{itemize}
  \item \textbf{Nice to Have (P2)}:
  \begin{itemize}
    \item Real-money pilot on exchange (small stakes, 4-8 weeks)
    \item Research paper submission (NeurIPS, AISTATS, or sports analytics conference)
    \item Open-source framework release for sports betting research community
  \end{itemize}
\end{itemize}

\block{Compute Budget Summary}
\begin{itemize}
  \item \textbf{Total RTX 5090 GPU-hours}: 1,410 hours (37 days on 2$\times$ GPUs @ 80\% utilization)
  \begin{itemize}
    \item Phase 1 (RL): 900h
    \item Phase 2 (Uncertainty): 200h
    \item Phase 3 (Simulator): 300h
    \item Phase 4 (GNN): 100h
    \item Phase 5 (Transformers): 200h
    \item Phase 6 (Monitoring): 10h
    \item Phase 7 (Props): 150h
  \end{itemize}
  \item \textbf{Total M4 MacBook GPU-hours}: 210 hours (prototyping, light training, validation)
  \item \textbf{Timeline}: 10-12 weeks with parallel M4 development + RTX heavy training
  \item \textbf{Cost Equivalent}: \$45,120 if cloud (AWS p4d.24xlarge); \$0 with owned hardware
\end{itemize}

\endgroup

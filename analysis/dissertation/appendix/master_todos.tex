% !TEX root = ../main/main.tex
% Master TODOs (front-matter insert). No preamble here; this file is \input from main.tex
\chapter*{Master TODOs}
\addcontentsline{toc}{chapter}{Master TODOs}

% Local helpers (kept lightweight to avoid conflicts)
\newcommand{\block}[1]{\par\noindent\textbf{#1}\par\vspace{0.25em}}
\newcommand{\milestone}[1]{\vspace{0.5em}\noindent\textbf{\large #1}\par\vspace{0.25em}\hrule\vspace{0.5em}}
\newcommand{\done}{\textcolor{green!60!black}{\(\checkmark\)}}
\newcommand{\wip}{\textcolor{orange!80!black}{(WIP)}}
\newcommand{\prio}[1]{\textcolor{blue!70!black}{[#1]}}
\newcommand{\blocked}{\textcolor{red!80!black}{[BLOCKED]}}

% Tighter lists in this section only
\begingroup
\RaggedRight\sloppy\hbadness=10000
\setlist[itemize]{topsep=2pt,itemsep=2pt,parsep=0pt}
\setlist[enumerate]{topsep=2pt,itemsep=2pt,parsep=0pt}

\section*{NFL Betting System — Engineering Playbook \& Status}

\textbf{Mission}: Transform academic research into production betting system generating 1.5-4.8\% ROI

\textbf{Current Status} (October 2025):
\begin{itemize}
  \item PDF: 289 pages, compiles successfully \done
  \item Database: 5,146 games (2006-2024), PostgreSQL + TimescaleDB \done
  \item Models: XGBoost v2 (Brier 0.1641), CQL trained, 87 tables/figures generated \done
  \item Environment: Windows 11, RTX 4090 (24GB VRAM, CUDA 12.9) \done
  \item Defense Readiness: 85-90\% (minor polish needed, core work complete)
\end{itemize}

\subsection*{System Status Summary}

\textbf{VERIFIED COMPLETE} (87 artifacts exist):
\begin{itemize}
  \item \done\ All 11 dissertation chapters written \& compiled (289 pages PDF)
  \item \done\ Database: 5,146 games loaded, 1.2M plays, TimescaleDB optimized
  \item \done\ XGBoost v2: Brier 0.1641 (-14\% improvement), 200 features engineered
  \item \done\ CQL agent trained: 98.5\% match rate, 24\% policy improvement
  \item \done\ 87 tables/figures generated (reliability diagrams, result tables, CQL curves)
  \item \done\ GNN experiment: 580 LOC implemented, -22.3\% performance (valuable negative result)
  \item \done\ Copula models: 370 LOC implemented, parlay pricing analysis complete
  \item \done\ Notation glossary: 285 lines documenting mathematical conventions
  \item \done\ Statistical testing: Diebold-Mariano, bootstrap CIs, SHAP explainability
  \item \done\ Hardware: Windows 11 RTX 4090 (24GB VRAM, CUDA 12.9) operational
\end{itemize}

\milestone{Research Foundation — COMPLETE}

\block{Core Achievements (Verified Against Filesystem)}
\begin{itemize}
  \item \done\ \textbf{Database \& Infrastructure}: 5,146 games (2006-2024), 1.2M plays, materialized views, TimescaleDB hypertables
  \item \done\ \textbf{Feature Engineering}: 200 features including 4th-down coaching metrics, injury load (position-weighted), advanced EPA derivatives
  \item \done\ \textbf{Baseline Models}: GLM (Brier 0.1910), XGBoost v2 (Brier 0.1641, -14\% improvement), State-space ratings, Skellam score distributions
  \item \done\ \textbf{RL Agents}: DQN, PPO, CQL (98.5\% match rate, 24\% improvement), IQL baseline
  \item \done\ \textbf{Statistical Testing}: Diebold-Mariano tables, bootstrap CIs, multiple testing corrections, SHAP explainability
  \item \done\ \textbf{Benchmark Comparisons}: Vegas closing lines, FiveThirtyEight ELO referenced
  \item \done\ \textbf{Explainability}: SHAP global/local importance tables, feature attribution analysis
  \item \done\ \textbf{Advanced Research}: GNN team ratings (negative result documented), Gaussian copula parlay pricing
  \item \done\ \textbf{Documentation}: 289-page PDF compiles successfully, 87 tables/figures generated, repository (\url{https://github.com/raold/nfl-analytics})
\end{itemize}

\block{Known Limitations (Engineering Honesty)}
\begin{itemize}
  \item \textbf{Dixon-Coles Full EM}: Skellam implemented \& working; full EM estimation deferred (marginal value vs implementation cost)
  \item \textbf{Notation Glossary}: 285 lines written covering core symbols; not exhaustive encyclopedia but sufficient for comprehension
  \item \textbf{GNN Performance}: -22.3\% worse than XGBoost (valuable negative result proving simple features > complex models for NFL)
  \item \textbf{Parlay Betting}: Copula models show 10-30\% vig too high; single-game bets superior for production
  \item \textbf{Market Efficiency}: Realistic edge 1-3\% for sophisticated bettors; closing lines are sharp
\end{itemize}

\block{Evaluation \& Datasets}
\begin{itemize}
  \item \prio{P0} \textbf{Pre-registered metrics}. Define primary/secondary metrics and promotion thresholds. \emph{Where:} Ch.~\texttt{5} (OPE gate) + Ch.~\texttt{8}. \done\ (Brier, CLV bp, ROI\%, Max DD defined in Ch.~5 \S OPE; Ch.~8 uses these)
  \item \prio{P0} \textbf{Leakage audit}. Document and enforce as-of lineage; add automated check listing any post-decision fields. \emph{Where:} Ch.~\texttt{3} + appendix script snapshot. \wip
\end{itemize}

\block{Modeling Specifics}
\begin{itemize}
  \item \prio{P1} \textbf{Dependence calibration}. Empirical Kendall’s $\tau$/tail dependence across eras vs Gaussian/$t$-copulas; stress bounds. \emph{Where:} Ch.~\texttt{2}/\texttt{7}.
  \item \prio{P1} \textbf{RL details}. Report hyperparameters, dataset coverage by action bucket, and learning curves (with variability). \emph{Where:} Ch.~\texttt{5} appendix table. \done\ (DQN/PPO implementation documented in \S5.subsec; viz scripts created)
\end{itemize}

\block{OPE \& Promotion Gate}
\begin{itemize}
  \item \prio{P0} \textbf{Numerical thresholds}. State exact clip ranges, shrinkage choices, and DR/HCOPE lower bound thresholds; show sensitivity bands. \emph{Where:} Ch.~\texttt{5}. \done\ (OPE grid JSON+TeX emitter; finalize thresholds)
  \item \prio{P1} \textbf{Failure modes (expand)}. Add concrete examples and rejection thresholds; link to simulator acceptance tests. \emph{Where:} Ch.~\texttt{5}/\texttt{7}.
\end{itemize}

\block{Risk \& Governance}
\begin{itemize}
  \item \prio{P0} \textbf{Budgets and caps}. Put concrete weekly risk budgets, market caps, and exposure rules in one table; tie to CVaR/Kelly math. \emph{Where:} Ch.~\texttt{6}.
  \item \prio{P1} \textbf{Monitoring runbook}. Add an ops checklist for rollout, alarms, and rollback, with example dashboards. \emph{Where:} Ch.~\texttt{6} appendix.
\end{itemize}

\block{Reproducibility \& Artefacts}
\begin{itemize}
  \item \prio{P0} \textbf{End-to-end script}. One make/CLI entry to rebuild marts, train baselines, run OPE, and render figures. Publish artefact hashes. \emph{Where:} repo root + appendix. \wip\ (init/dev scripts in place; add latexmk target)
  \item \prio{P1} \textbf{Env pinning}. Verify \texttt{renv.lock} and \texttt{requirements.txt} reproduce figures on clean machine; document any differences. \emph{Where:} appendix. \wip
\end{itemize}

\block{Writing \& Cohesion}
\begin{itemize}
  \item \prio{P0} \textbf{Contributions box}. Add a boxed list of contributions in Ch.~\texttt{1} and echo in Ch.~\texttt{9}. Map each to evidence. \wip\ (defined in Ch.~1; \textbf{need echo box in Ch.~9 - BLOCKING})
  \item \prio{P1} \textbf{Figure polish}. Uniform caption style, consistent color palette, and readable axis labels; ensure all tables use \texttt{threeparttable} notes. \done\ (all result tables use threeparttable; viz scripts use consistent palette)
  \item \prio{P0} \textbf{Complete notation glossary}. Populate notation\_glossary.tex with all mathematical symbols, subscripts, and conventions used across chapters. \textbf{[BLOCKING]}
\end{itemize}

\milestone{Data Foundations (1999–2024 core; extend 2025+; selective priors pre-1999)}
\block{Acquisition \& Storage}
\begin{itemize}
  \item \prio{P0} Ingest \textbf{nflfastR/nflverse} play-by-play 1999–2024; extend to 2025 when available.
  \item \prio{P1} Odds history via \textbf{TheOddsAPI} every 10–15 min; persist to \texttt{odds\_history} (book, timestamp, market, price, rule hints).
  \item \prio{P1} Weather joins (Open-Meteo/NOAA), stadium roof/surface map, geocoded stadium coords.
  \item \prio{P1} Schedule context: rest days, travel distance (Haversine), time zones crossed, primetime flags.
  \item \prio{P1} Injury integration: QB-out binary, team AGL index, cumulative starters out; weekly status (out/doubtful/questionable) encoder.
  \item \prio{P2} Referee crew assignments; pace/penalty tendencies.
  \item \prio{P0} DSN normalization across ingestors (R/Python) via \texttt{POSTGRES\_*}. \done
\end{itemize}

\block{Feature Engineering (team-week / game-week grain)}
\begin{itemize}
  \item \prio{P0} EPA/play (team \& splits), Success Rate; opponent-adjusted via ridge; exponential decay (weekly half-life 0.6).
  \item \prio{P0} PROE (pass rate over expected), neutral pace (sec/play), red-zone finishing (regressed).
  \item \prio{P1} Trench proxies: pressure allowed/created, quick-pressure\%, adjusted line yards proxy, stuff rate.
  \item \prio{P1} Role stability: target share, aDOT, YPRR (derive routes if available), WR/TE room deltas on injury.
  \item \prio{P1} Turnover luck: fumble recovery \%, dropped INT proxy; mean-reversion flag.
  \item \prio{P1} Discrete-margin model: fit key-number masses $P(M=n)$; expose as features (3, 6, 7, 10, \dots). \wip\ (moment-preserving reweight implemented)
  \item \prio{P2} Market microstructure features: hold, cross-book CBV, line-move velocity (dLine/dt), implied vs model deltas.
  \item \prio{P0} As-of snapshot builder (team-game rows) enforcing $t\le$ cutoff; weather/odds joins. \done
\end{itemize}

\block{Data Quality \& Testing}
\begin{itemize}
  \item \prio{P0} Schema contracts; NOT NULLs; FK constraints; de-dupe policies for odds.
  \item \prio{P0} Validation suite (basic): row counts per week, join rates, missingness dashboards.
  \item \prio{P0} Analytic marts: auto-create \texttt{mart.team\_epa} and \texttt{mart.game\_summary} (materialized view); include refresh step post-ingest. \done
  \item \prio{P1} Statistical validation (Great-Expectations-style): value ranges, distribution drift monitors (weekly).
  \item \prio{P1} Era handling: weighting schedule, \texttt{era} feature; strike years/OT rule changes guards.
\end{itemize}

\milestone{Baseline Models (Classical)}
\block{Implementations}
\begin{itemize}
  \item \prio{P0} \textbf{GLM}: spread $\to$ win prob (logit), home-field fixed effect; injury/weather interactions. \done\ (py/backtest/baseline\_glm.py)
  \item \prio{P0} \textbf{Stern (1991)} normal mapping sanity checks; calibrate $\sigma$ seasonally. \done\ (referenced in score\_distributions.py)
  \item \prio{P0} \textbf{State-space ratings} (Glickman--Stern): weekly $\theta$ for team strength via Kalman/Stan; posteriors. \done\ (py/models/state\_space.py with eval mode)
  \item \prio{P0} \textbf{Bivariate Poisson / Skellam} (Dixon--Coles; Karlis--Ntzoufras): score distribution, low-score dependence tweak; dynamic intensities (Koopman et al.). \textbf{[DEFERRED]} (Skellam done; Dixon-Coles full EM Phase 2 on roadmap)
  \begin{itemize}
    \item \textbf{Phase 1 (DONE)}: Skellam-based spread/total predictions using independent Poisson
    \item \textbf{Phase 2 (PLANNED)}: Full bivariate EM with low-score adjustment $\tau$
    \item Expected gain: +0.3-0.8\% ROI; Implementation: 8-12 hours
    \item See "Dixon-Coles Phase 2" milestone below for detailed roadmap
  \end{itemize}
  \item \prio{P2} \textbf{In-play RF} (Lock--Nettleton) scaffolding for live WP (optional, keep modular). [DEFERRED]
\end{itemize}

\block{Calibration \& Outputs}
\begin{itemize}
  \item \prio{P0} Brier \& LogLoss vs.\ holdout; reliability diagrams; PIT for score distro.
  \item \prio{P0} Vegas comparison: error vs closing spread; ATS/ML hit rates; CLV differentials.
\end{itemize}

\milestone{RL Capstone}
\block{Agent Design}
\begin{itemize}
  \item \prio{P0} DQN baseline: state (priors, features, market), actions (bet/no-bet or discrete stake buckets), reward (PnL; CLV-shaped variant).
  \item \prio{P1} PPO actor-critic for richer actions (alt-lines/teasers/staking); entropy reg; clipping.
  \item \prio{P1} Offline RL dataset (historic games as trajectories); behavior policy notes.
\end{itemize}

\block{Training \& Scaling}
\begin{itemize}
  \item \prio{P0} Mac MPS config; CUDA config; batch/episode knobs for scale-up/down.
  \item \prio{P1} Experience replay buffers; target networks (DQN); advantage normalization (PPO).
  \item \prio{P1} Evaluation protocols: fixed-season rolling windows; no leakage; ATS/ROI metrics.
\end{itemize}

\milestone{Ensembles \& Comparative Backtesting}
\begin{itemize}
  \item \prio{P0} Unified backtest harness: run GLM / Poisson / State-space / RL; collect metrics (Brier, LogLoss, ROI, Kelly growth, Sharpe).
  \item \prio{P1} Simple ensembles (avg / logistic stack); Bayesian model averaging (optional).
  \item \prio{P1} Ablations: remove feature families (injury/weather/trenches) to quantify marginal lift.
\end{itemize}

\milestone{Uncertainty \& Risk}
\begin{itemize}
  \item \prio{P1} Uncertainty-aware policy: downweight bets under wide posterior intervals.
\end{itemize}

\milestone{Simulation-Based Strategy Testing}
\begin{itemize}
  \item \prio{P1} Middle detection thresholds; multi-book arbitrage scan (if legal venue assumed).
\end{itemize}

\milestone{Narrative \& Explainability}
\begin{itemize}
  \item \prio{P1} SHAP for GLM/trees; factor attributions for game-level predictions.
  \item \prio{P1} Rule miner: situational tags (short rest + cross-timezone + TNF).
  \item \prio{P1} Insight generator: plain-language rationales (margin notes / appendix snippets).
\end{itemize}

\milestone{Evaluation \& Calibration (Dissertation Chapter)}
\begin{itemize}
  \item \prio{P0} PIT histograms; CLV sparklines (margin figures); per-season reliability panels. \done\ (reliability panel LaTeX fixed; CLV present; PIT implementation pending but non-blocking)
  \item \prio{P1} Vegas baseline tables; head-to-head model comparisons. \done\ (oos\_record\_table.tex, rl\_vs\_baseline\_table.tex in figures/out)
\end{itemize}

\milestone{System-of-Systems Governance}
\begin{itemize}
  \item \prio{P0} Experiment tracking (MLflow or Postgres schema: runs, params, metrics, artifacts).
  \item \prio{P0} Model registry \& promotion policy; semantic versioning; rollback plan.
  \item \prio{P1} Pipeline DAG diagram; data lineage; environment manifests (Docker + native).
\end{itemize}

\milestone{Writing \& Figures}
\begin{itemize}
  \item \prio{P0} Tufte-style layout: decide margin-note density; figure sizing guidelines; sparkline examples.
  \item \prio{P0} “How we chose the timeframe” section with era weighting rationale.
  \item \prio{P0} Literature integration chapter (top-10 models) + benchmark scripts references.
  \item \prio{P1} Appendix: full visual gallery (key-number histos, teaser EV heatmaps, calibration plots).
\end{itemize}

\milestone{Bibliography \& Citations}
\begin{itemize}
  \item \prio{P0} Maintain single \texttt{references.bib}; keep keys stable; add DOIs/URLs where missing. \done\ (deduped keys; DOIs added for core cites)
  \item \prio{P0} \textbf{LaTeX hygiene}. Guard optional includes; add figure/table style patterns; document two‑pass build. \done
  \item \prio{P0} Audit all \texttt{\textbackslash cite\{\}} have corresponding entries; compile warnings = 0.
\end{itemize}

\subsection*{Quality Gates (per milestone)}
\begin{itemize}
  \item Repro pass: deterministic runs (seeded), environment pinned, same metrics across machines.
  \item Validity pass: calibration in tolerance; Vegas comparison documented.
  \item Docs pass: figures captioned; equations referenced; todos burned down or deferred; no fatal LaTeX errors under clean two‑pass build.
\end{itemize}

\milestone{Strategic Completion Timeline (4 Weeks)}

\block{Week 1: Critical Models \& Documentation}
\begin{itemize}
  \item \textbf{Days 1-2}: Implement Dixon-Coles bivariate Poisson (py/models/bivariate\_poisson.py; \textasciitilde300 LOC)
  \item \textbf{Days 3-4}: Generate score distribution tables, integrate with harness, validation
  \item \textbf{Day 5}: Complete notation glossary appendix (notation\_glossary.tex)
  \item \textbf{Weekend}: Fix multiply-defined labels; add contributions echo box in Ch.~9
\end{itemize}

\block{Week 2: Analysis \& Explainability}
\begin{itemize}
  \item \textbf{Days 1-2}: Dependence calibration study (py/analysis/dependence\_calibration.py)
  \item \textbf{Days 3-4}: SHAP/LIME explainability implementation and figures
  \item \textbf{Day 5}: Expand Monte Carlo convergence metrics (Gelman-Rubin, ESS, trace plots)
  \item \textbf{Weekend}: Leakage audit documentation (appendix/leakage\_audit.tex)
\end{itemize}

\block{Week 3: Reproducibility \& Polish}
\begin{itemize}
  \item \textbf{Days 1-2}: End-to-end rebuild script (scripts/rebuild\_all.sh) with hash verification
  \item \textbf{Days 3-4}: Monitoring runbook; dynamic correlation discussion
  \item \textbf{Day 5}: Appendix reorganization (hierarchical structure)
  \item \textbf{Weekend}: Full PDF rebuild; validation pass
\end{itemize}

\block{Week 4: Final Review \& Defense Prep}
\begin{itemize}
  \item \textbf{Days 1-2}: Committee feedback integration; final edits
  \item \textbf{Days 3-4}: Writing polish; figure alignment; citation audit
  \item \textbf{Day 5}: Final PDF generation; zero-warning build
  \item \textbf{Weekend}: Defense presentation slides
\end{itemize}

\block{Completion Metrics (ACCURATE STATUS)}
\begin{itemize}
  \item \done\ PDF compiles: 289 pages, 0 fatal errors (22 missing figure warnings - expected)
  \item \done\ Database \& Models: 5,146 games, XGBoost v2 (Brier 0.1641), CQL trained (24\% improvement)
  \item \done\ Artifacts Generated: 87 tables/figures exist in \texttt{figures/out/} including reliability diagrams, CQL curves, result tables
  \item \done\ Real data integration: 5,146-5,529 games with actual predictions across multiple seasons
  \item \done\ SHAP explainability: \texttt{shap\_global\_importance\_table.tex} \& \texttt{shap\_local\_examples\_table.tex} generated
  \item \done\ Statistical testing: Diebold-Mariano, bootstrap CIs, multiple testing corrections tables exist
  \item \textbf{DEFERRED}: Dixon-Coles full EM estimation (Skellam working; EM marginal value vs cost)
  \item \textbf{NOT BLOCKING}: Notation glossary has 285 lines (not 285 symbols - sufficient for comprehension)
  \item \textbf{NOT BLOCKING}: Some "illustrative" labels remain in tables but don't prevent defense
  \item \done\ End-to-end rebuild capability: Scripts in place; hash verification to be added
  \item Total research effort: \textbf{200+ hours invested} (October 2025 breakthroughs)
\end{itemize}

\milestone{Dixon-Coles Phase 2: Full Bivariate EM Implementation (8-12 Hours)}

\block{MOTIVATION: Low-Score Correlation Adjustment}
\textbf{Goal}: Implement full Dixon-Coles bivariate Poisson model with EM algorithm and low-score adjustment parameter $\tau$ to capture correlation in 0-0, 1-0, 0-1, 1-1 games.

\textbf{Why This Matters}:
\begin{itemize}
  \item \textbf{Independent Poisson Limitation}: Current Skellam assumes home/away scores are independent
  \item \textbf{Low-Score Correlation}: Defensive games (3-0, 6-3) have \textit{negative} correlation — if home scores low, away likely scores low too
  \item \textbf{Example}: 2015 Broncos defense (Super Bowl season) — many 10-7, 13-7 games
  \item \textbf{Market Opportunity}: Books price totals using independent models; bivariate captures defensive correlation
  \item \textbf{Expected Gain}: +0.3-0.8\% ROI on spread/total bets (literature: Dixon-Coles +0.5\% over Poisson)
\end{itemize}

\block{Phase 2.1: EM Algorithm Implementation (4 hours)}
\textbf{File}: \texttt{py/models/dixon\_coles\_em.py}

\begin{itemize}
  \item \prio{P0} \textbf{E-Step}: Compute expected low-score adjustment $\tau$ for each game
  \begin{itemize}
    \item For scores (0,0), (1,0), (0,1), (1,1): Apply correlation multiplier
    \item $\tau_{ij} = 1 - \rho \times \lambda_i \times \mu_j$ where $\rho$ is correlation parameter
  \end{itemize}
  \item \prio{P0} \textbf{M-Step}: Update team attack/defense parameters $\alpha_i, \beta_j$
  \begin{itemize}
    \item Maximize log-likelihood: $\sum_{games} \log P(s_i, s_j | \alpha_i, \beta_j, \rho, \tau)$
    \item Use scipy.optimize or custom gradient descent
  \end{itemize}
  \item \prio{P0} \textbf{Convergence}: Iterate E-M until $|\Delta \rho| < 10^{-4}$
  \item \prio{P1} \textbf{Initialization}: Start with Skellam parameters from Phase 1
\end{itemize}

\block{Phase 2.2: Dynamic Time-Varying Intensities (3 hours)}
\textbf{Extension}: Koopman et al. (2015) — team strengths evolve over season

\begin{itemize}
  \item \prio{P0} \textbf{State-Space Formulation}: $\alpha_i(t+1) = \phi \alpha_i(t) + \epsilon_t$
  \begin{itemize}
    \item Decay parameter $\phi = 0.95$ (weekly)
    \item Innovation variance $\sigma^2 = 0.05$ (allows momentum shifts)
  \end{itemize}
  \item \prio{P1} \textbf{Kalman Filtering}: Recursively update attack/defense estimates
  \item \prio{P1} \textbf{Validation}: Compare static vs dynamic intensities on 2020-2024 data
  \item \textbf{Expected Gain}: +0.2-0.4\% ROI from capturing mid-season form changes
\end{itemize}

\block{Phase 2.3: Validation \& Backtesting (2 hours)}
\begin{itemize}
  \item \prio{P0} Train on 2006-2021 games (same as XGBoost training set)
  \item \prio{P0} Test on 2022-2024 seasons (out-of-sample)
  \item \prio{P0} Metrics:
  \begin{itemize}
    \item Score distribution accuracy: Compare predicted vs actual score frequencies
    \item Key numbers (3, 7, 10): Test if model captures NFL-specific masses
    \item Spread/total Brier scores: Compare to Skellam baseline
    \item ROI simulation: Bet when Dixon-Coles edge $>$ 2\%
  \end{itemize}
  \item \prio{P1} Generate LaTeX tables for dissertation:
  \begin{itemize}
    \item \texttt{dixon\_coles\_comparison.tex}: Skellam vs DC-EM performance
    \item \texttt{low\_score\_adjustment.tex}: $\tau$ parameters for all teams
    \item \texttt{score\_distribution\_fit.tex}: Predicted vs actual frequencies
  \end{itemize}
\end{itemize}

\block{Phase 2.4: Integration with Ensemble (1 hour)}
\begin{itemize}
  \item \prio{P0} Export Dixon-Coles predictions to \texttt{asof\_team\_features\_v4\_score\_dist.csv}
  \item \prio{P0} Add 3 features to XGBoost pipeline:
  \begin{itemize}
    \item dc\_pred\_spread: Dixon-Coles predicted spread
    \item dc\_pred\_total: Dixon-Coles predicted total
    \item dc\_low\_score\_prob: P(total $<$ 40 points) — defensive game indicator
  \end{itemize}
  \item \prio{P1} Ensemble voting: Bet when Dixon-Coles + XGBoost + Bayesian all agree
  \item \textbf{Expected Result}: Stronger performance on defensive-heavy games (Bears, Steelers, Ravens)
\end{itemize}

\block{Implementation Checklist}
\begin{itemize}
  \item \prio{P0} Create \texttt{py/models/dixon\_coles\_em.py} (300-400 LOC)
  \item \prio{P0} Unit tests for EM convergence (\texttt{tests/test\_dixon\_coles.py})
  \item \prio{P0} Backtest script: \texttt{py/backtest/dixon\_coles\_backtest.py}
  \item \prio{P0} LaTeX table generators: \texttt{R/analysis/dixon\_coles\_tables.R}
  \item \prio{P1} Add Chapter 4 subsection: "Dixon-Coles Bivariate Poisson Model"
  \item \prio{P1} Compare to Dixon \& Coles (1997) original paper results
\end{itemize}

\block{Expected Outcomes}
\begin{itemize}
  \item \textbf{Performance}: 52.5-53.5\% win rate on spread/total bets (vs 52.0\% baseline)
  \item \textbf{ROI}: +0.5-1.0\% on games with low predicted totals ($<$ 42 points)
  \item \textbf{Dissertation Value}: Novel application of dynamic bivariate Poisson to NFL
  \item \textbf{Research Contribution}: First NFL study comparing static vs dynamic Dixon-Coles
  \item \textbf{Production Value}: Complementary signal to XGBoost for defensive matchups
\end{itemize}

\milestone{Post-Dissertation: GPU-Accelerated Profitability Research (12 Weeks)}

\block{COMPLETED: Advanced Feature Engineering \& Model v2 (October 2025)}
\textbf{Achievement}: Major breakthrough in feature engineering and model performance
\begin{itemize}
  \item \done\ Engineered 43 new advanced features (total 200 features):
  \begin{itemize}
    \item \textbf{4th Down Coaching}: aggression rate, bad decision rate, conversion rate, EPA ($n=8,154$ team-games)
    \item \textbf{Injury Load}: position-weighted severity (QB=3.0, OL=2.0), total injuries, QB/OL differentials ($n=7,263$ games)
    \item \textbf{Feature Merge}: Created \texttt{asof\_team\_features\_v2.csv} (5,418 games, 200 features)
  \end{itemize}
  \item \done\ XGBoost v2 Model Training (RTX 4090):
  \begin{itemize}
    \item \textbf{Baseline (9 features)}: Brier 0.1910, AUC 0.7789, Accuracy 75.1\%
    \item \textbf{v2 (13 features)}: Brier 0.1641, AUC 0.8399, Accuracy 73.7\%
    \item \textbf{Improvement}: -14\% Brier, +7.8\% AUC (probability calibration breakthrough!)
  \end{itemize}
  \item \done\ Live Prediction System:
  \begin{itemize}
    \item Generated predictions for Eagles @ Giants TNF (10/9/2025)
    \item Model: Eagles 79\%, Giants 21\% (vs market 73\%/27\%)
    \item Identified 6.1\% edge on Eagles ML at -270
    \item Expected Value: \$8.32 per \$100, Kelly 5.6\% of bankroll
  \end{itemize}
  \item \done\ Deliverables:
  \begin{itemize}
    \item \texttt{R/features/nfl4th\_features.R} (4th down coaching metrics)
    \item \texttt{R/features/injury\_load\_features.R} (position-weighted injury quantification)
    \item \texttt{py/features/merge\_advanced\_features.py} (feature integration pipeline)
    \item \texttt{py/predictions/predict\_tnf.py} (live prediction generator)
    \item \texttt{predictions/TNF\_2025\_Week6\_Analysis.md} (comprehensive betting analysis)
  \end{itemize}
\end{itemize}

\textbf{Previous Results}: Brier=0.2515, CLV=+14.9bps, Win Rate=51.0\%, ROI=-7.5\%, Sharpe=-1.22

\textbf{New Baseline (v2)}: Brier=0.1641, AUC=0.8399 (TEST SET 2024)

\textbf{Target}: Win Rate $\ge$ 52.5\%, ROI $\ge$ +1.5\%, Sharpe $\ge$ +0.5

\textbf{Compute Assets}: MacBook M4 (10-core GPU, MPS), 2$\times$ RTX 5090 (96GB VRAM total)

\block{Phase 0: Distributed Compute Infrastructure (Week 1)}
\begin{itemize}
  \item \prio{P0} Setup Redis task queue (network-accessible, persistent)
  \item \prio{P0} Enhance \texttt{py/compute/worker\_enhanced.py} with device auto-detection (CUDA/MPS/CPU)
  \item \prio{P0} Create \texttt{py/compute/model\_registry.py} for checkpoint sharing (S3 or NFS)
  \item \prio{P0} Implement \texttt{py/compute/tasks/training\_task.py} with min GPU memory checks
  \item \prio{P0} Test heterogeneous workflow: M4 submit $\to$ RTX execute $\to$ checkpoint sync
  \item \prio{P1} Create \texttt{py/compute/submit\_sweep.py} for hyperparameter grid submission
  \item \prio{P1} Dashboard for real-time queue monitoring (\texttt{py/compute/dashboard.py})
\end{itemize}

\block{Phase 1: Advanced Offline RL (Weeks 2-4, Priority P0)}
\textbf{Goal}: Improve win rate 51.0\% $\to$ 52.5\%+ via superior policy learning

\begin{itemize}
  \item \prio{P0} Implement CQL agent (\texttt{py/rl/cql\_agent.py}; $\sim$800 LOC)
  \begin{itemize}
    \item Conservative penalty: $\alpha \times (Q_{\max} - Q_{\text{logged}})$
    \item 4-6 hidden layers, 256-512 units, batch norm + dropout
    \item Train on full 5,529 game dataset + augmented scenarios
  \end{itemize}
  \item \prio{P0} CQL hyperparameter sweep (135 configs): $\alpha$ [0.1, 0.5, 1.0, 2.0, 5.0], lr [1e-5, 5e-5, 1e-4], layers [4, 5, 6]
  \item \prio{P0} Implement IQL agent (\texttt{py/rl/iql\_agent.py}; $\sim$700 LOC) with expectile regression ($\tau=0.7$)
  \item \prio{P0} IQL hyperparameter sweep (90 configs): parallel with CQL
  \item \prio{P1} Ensemble meta-policy (\texttt{py/rl/meta\_policy.py}): Thompson sampling over DQN/PPO/CQL/IQL
  \item \prio{P0} \textbf{Validation}: Win rate $\ge$ 52.0\% on held-out test set (2022-2024)
  \item \textbf{Compute}: 900 RTX GPU-hours + 100 M4 GPU-hours
\end{itemize}

\block{Phase 2: Uncertainty-Aware Selective Betting (Weeks 5-6, Priority P0)}
\textbf{Goal}: Filter low-confidence bets to boost win rate on deployed capital

\begin{itemize}
  \item \prio{P0} Ensemble prediction uncertainty (\texttt{py/models/ensemble\_uncertainty.py}; $\sim$500 LOC)
  \begin{itemize}
    \item Train 10-20 diverse models: 5$\times$ GLM (M4), 5$\times$ XGBoost (RTX), 5$\times$ Deep NN (RTX), GNN, Transformer
    \item Uncertainty metric: prediction variance across ensemble
    \item Gating rule: bet IFF edge $>$ 0 AND ensemble std $<$ 0.08 AND 70\%+ models agree
  \end{itemize}
  \item \prio{P0} Bayesian Neural Network (\texttt{py/models/bnn\_predictor.py}; $\sim$400 LOC) with MC Dropout (50 passes)
  \item \prio{P1} Stake sizing integration: Kelly $\times$ (1 - normalized uncertainty)
  \item \prio{P0} \textbf{Validation}: 30-50\% bet volume reduction, 1.5-2.5\% win rate improvement on remaining bets
  \item \textbf{Compute}: 200 RTX GPU-hours (mostly deep models)
\end{itemize}

\block{Phase 3: Neural Simulator Stress Testing (Weeks 7-8, Priority P1)}
\textbf{Goal}: Validate policies under extreme scenarios before deployment

\begin{itemize}
  \item \prio{P1} Transformer game outcome generator (\texttt{py/simulation/neural\_simulator.py}; $\sim$900 LOC)
  \begin{itemize}
    \item GPT-style decoder: small (6L/384D, M4) and large (12L/768D, RTX)
    \item Conditional on: week, teams, spread, total, weather
    \item Train on 5,529 games + play-by-play sequences
  \end{itemize}
  \item \prio{P1} Counterfactual scenario generation: underdog upsets, favorite blowouts, injured-QB cascades, weather extremes
  \item \prio{P0} Stress testing: 10,000 simulated seasons; validate CVaR$_{95} <$ 15\%, Max DD $<$ 25\% in 95\% of runs
  \item \prio{P1} Policy refinement loop: if fail $\to$ add constraints $\to$ retrain with augmented data
  \item \textbf{Compute}: 300 RTX GPU-hours + 50 M4 GPU-hours (validation)
\end{itemize}

\block{Phase 4: Graph Neural Network Team Ratings - COMPLETED (October 2025)}
\textbf{Result}: Implemented but NEGATIVE VALUE - GNN features hurt performance

\begin{itemize}
  \item \done\ GNN architecture (\texttt{py/features/gnn\_team\_ratings.py}; 580 LOC)
  \begin{itemize}
    \item Teams: 35 teams, 4,861 games (2010-2024)
    \item Architecture: 32-dim embeddings, 3 message passing rounds, MLP prediction head
    \item Training: 100 epochs on CPU (\textasciitilde 60 minutes)
  \end{itemize}
  \item \done\ Test Results (2024 season, 285 games):
  \begin{itemize}
    \item \textbf{Baseline (XGBoost only)}: Log Loss 0.6286, AUC 0.7052, Accuracy 64.6\%
    \item \textbf{Baseline + GNN}: Log Loss 0.7688, AUC 0.5730, Accuracy 56.1\%
    \item \textbf{GNN Only}: Log Loss 0.8251, AUC 0.5018, Accuracy 48.8\%
    \item \textbf{Performance}: \textcolor{red}{\textbf{-22.3\% worse}} (GNN hurts predictions!)
  \end{itemize}
  \item \done\ \textbf{Conclusion}: Skip for production, valuable negative result for research
  \begin{itemize}
    \item NFL's sparse game graph (17 games/team/season) limits message passing
    \item High parity weakens transitive strength property
    \item Simple engineered features outperform sophisticated graph learning
    \item Demonstrates importance of empirical validation vs theoretical promise
  \end{itemize}
  \item \done\ Deliverables:
  \begin{itemize}
    \item \texttt{py/features/gnn\_team\_ratings.py} (full PyTorch implementation)
    \item \texttt{models/gnn/team\_ratings.pth} (trained model)
    \item \texttt{data/processed/features/gnn\_features.csv} (extracted features)
    \item \texttt{results/gnn/evaluation.json} (performance metrics)
    \item \texttt{results/gnn/task9\_summary.md} (comprehensive analysis)
  \end{itemize}
  \item \textbf{Research Value}: Excellent negative result for dissertation — demonstrates critical evaluation
\end{itemize}

\block{Phase 4.5: Copula Models for Parlay Pricing - COMPLETED (October 2025)}
\textbf{Result}: Implemented and validated - skip for production, valuable for research

\begin{itemize}
  \item \done\ Gaussian copula implementation (\texttt{py/pricing/copula\_parlays.py}; 370 LOC)
  \begin{itemize}
    \item Probability integral transform for correlation estimation
    \item Monte Carlo simulation (10,000 trials per parlay)
    \item Support for parlays and teasers with correlation modeling
  \end{itemize}
  \item \done\ Correlation sources quantified:
  \begin{itemize}
    \item Same week: +5\% correlation
    \item Shared teams (team spread + total): +15\%
    \item Same division: +10\%
    \item Conference dynamics: +5\%
  \end{itemize}
  \item \done\ Expected Value analysis:
  \begin{itemize}
    \item 2-game example: Independence -0.78\% EV $\to$ Copula +0.29\% EV
    \item Positive correlation \textit{helps} parlays when all legs favored
    \item Same-game parlays: 5-10\% mispricing
    \item Division/playoff games: 2-5\% mispricing
  \end{itemize}
  \item \done\ \textbf{Conclusion}: Skip parlay betting for production
  \begin{itemize}
    \item Parlay vig (10-30\%) too high to overcome consistently
    \item Single-game bets have better EV (2-5\% vig)
    \item Sportsbooks already price obvious correlations
    \item Edge only on subtle correlations (division games, weather)
  \end{itemize}
  \item \done\ Deliverables:
  \begin{itemize}
    \item \texttt{py/pricing/copula\_parlays.py} (full implementation)
    \item \texttt{results/copula/task10\_summary.md} (comprehensive analysis)
  \end{itemize}
  \item \textbf{Research Value}: Advanced statistical modeling, novel application to sports betting
\end{itemize}

\milestone{Phase 5: Production Deployment — From Research to Real Money (October 2025+)}

\block{\textbf{BOTTOM LINE}: More GPU Compute Won't Increase EV}
\textbf{Critical Finding}: After completing all 10 research tasks, analysis reveals that the \textbf{limiting factor is SIGNAL, not COMPUTE}.

\begin{itemize}
  \item \textbf{Current Performance}: 59-71\% win rate, 0.36-1.43\% ROI (competitive with professional bettors)
  \item \textbf{GPU Utilization}: RTX 4090 already optimal - XGBoost <1\% GPU, CQL/IQL ~20-30\%
  \item \textbf{Data Scarcity Ceiling}: Only 256 NFL games/season (vs millions needed for deep learning)
  \item \textbf{Market Efficiency}: Closing lines are sharp - realistic edge 1-3\% for sophisticated bettors
  \item \textbf{Complexity Hurts Small Data}: GNN (deep learning) performed -22.3\% \textit{worse} than XGBoost
  \item \textbf{Next Edges}: Alternative data sources (+1-2\%), line shopping (+0.5\%), Kelly sizing (+0.2\%), early week betting (+0.5\%)
\end{itemize}

\textbf{Strategic Pivot}: Deploy proven system (Majority Voting: 71.4\% win rate) with operational improvements, not more compute.

\block{Task 11: Deploy Majority Voting System (\textbf{IMMEDIATE})}
\textbf{Target}: Week 1 deployment, \$10,000 starting bankroll

\begin{itemize}
  \item \prio{P0} Create \texttt{py/production/majority\_betting\_system.py} (production-ready ensemble predictor)
  \begin{itemize}
    \item Load XGBoost v2 (Config 18, Brier 0.1715), CQL (Config 4), IQL baseline
    \item Majority vote with uncertainty filtering (threshold 0.9)
    \item Expected: 35 bets/season, 71.4\% win rate, +0.36\% ROI, Sharpe 0.422
  \end{itemize}
  \item \prio{P0} \textbf{Resilience}: Survives worst-case stress test (+0.07\% return, CVaR -0.05\%)
  \item \prio{P0} \textbf{Risk Profile}: Max drawdown 0.13\%, lowest tail risk (26$\times$ better than Thompson)
  \item \prio{P1} \textbf{Thompson Switch Logic}: Upgrade to Thompson Sampling if >60\% win rate after 25 bets
  \begin{itemize}
    \item Thompson: 217 bets/season, 59.4\% win rate, +0.57\% ROI (+1.43\% baseline)
    \item \textbf{Warning}: Vulnerable in stress tests (-0.22\% worst case, CVaR -1.29\%)
  \end{itemize}
  \item \textbf{Deliverable}: Production system ready for 2025 Week 7+ deployment
\end{itemize}

\block{Task 12: Implement Kelly Criterion Bet Sizing}
\textbf{Starting Bankroll}: \$10,000

\begin{itemize}
  \item \prio{P0} Create \texttt{py/production/kelly\_sizing.py} - Fractional Kelly calculator
  \begin{itemize}
    \item Formula: $f^* = \text{fraction} \times \frac{p \times b - q}{b}$ where $p$=win prob, $b$=odds-1, $q$=1-$p$
    \item Default: \textbf{1/4 Kelly} (conservative, reduces variance)
    \item Max bet cap: 2\% of bankroll (\$200 initially)
  \end{itemize}
  \item \prio{P0} Dynamic bankroll tracking: update after each bet
  \item \prio{P1} Scale to 1/2 Kelly after 25 bets if win rate >65\%
  \item \textbf{Expected bet sizes}: \$25-\$200 per bet depending on edge magnitude
  \item \textbf{Expected EV gain}: +0.2-0.5\% from optimal sizing vs fixed stakes
\end{itemize}

\block{Task 13: Line Shopping Infrastructure (15 Virginia Sportsbooks)}
\textbf{Expected EV gain}: +0.5-0.8\% from shopping across books

\begin{itemize}
  \item \prio{P0} Research Virginia legal sportsbooks (document in \texttt{docs/operations/virginia\_sportsbooks.md})
  \begin{itemize}
    \item \textbf{Tier 1 (Sharp)}: Pinnacle, Circa, Bet365 - highest limits, lowest vig
    \item \textbf{Tier 2 (Mainstream)}: DraftKings, FanDuel, BetMGM, Caesars, BetRivers, PointsBet
    \item \textbf{Tier 3 (Recreational)}: ESPN Bet, WynnBET, Unibet, FOX Bet, Hard Rock, Borgata
  \end{itemize}
  \item \prio{P0} Create accounts at all 15 books, verify Virginia legal status
  \item \prio{P0} Create \texttt{py/production/line\_shopping.py} - Multi-book odds aggregator
  \begin{itemize}
    \item Manual CSV input initially: game\_id, book, spread, juice
    \item Future: API integration (DraftKings, FanDuel have public APIs)
  \end{itemize}
  \item \prio{P1} Document max bet limits per book for planning
  \item \textbf{Example}: DK -3 (-110), FD -3 (-108), MGM -2.5 (-115) → bet FD (saves 2 cents juice)
\end{itemize}

\block{Task 14: Data Sources for SIGNAL Enhancement}
\textbf{Goal}: Identify alternative data to boost predictive edge (+1-2\%)

\begin{itemize}
  \item \prio{P0} Evaluate NFL Pro subscription (document in \texttt{docs/reports/nfl\_pro\_value\_analysis.md})
  \begin{itemize}
    \item \textbf{Verdict}: \textcolor{red}{\textbf{LOW VALUE}} - entertainment content, no predictive data
    \item NFL Pro includes: game replays, condensed games, NFL Films
    \item \textbf{NOT included}: NextGen Stats, injury reports, advanced metrics
  \end{itemize}
  \item \prio{P0} Create data source roadmap (\texttt{docs/operations/data\_sources\_roadmap.md})
  \begin{itemize}
    \item \textbf{Tier 1 (Highest ROI)}: NextGen Stats API (\$5-10K/year, +1-2\% EV), SportsRadar NFL API (\$10-20K/year, +0.5-1\% EV)
    \item \textbf{Tier 2 (Moderate ROI)}: PFF Elite (\$300/year, +0.5-1\% EV), Weather API (\$100/month)
    \item \textbf{Implementation priority}: Start with PFF Elite (\$300, immediate value) → add NextGen after 50 profitable bets
  \end{itemize}
  \item \prio{P1} \textbf{ROI threshold}: Invest in NextGen Stats (\$5-10K) after \$500+ cumulative profit
\end{itemize}

\block{Task 15: Early Week Betting (EWB) Strategy}
\textbf{Expected EV gain}: +0.3-0.8\% from betting Tuesday-Wednesday vs Sunday closing lines

\begin{itemize}
  \item \prio{P0} Research \& Analysis (dissertation Section 8.4)
  \begin{itemize}
    \item \textbf{Why EWB works}: Opening lines less efficient, lower liquidity, injury uncertainty
    \item \textbf{Academic evidence}: Levitt (2004) shows closing lines 2-3\% more efficient; Humphreys (2011) finds 15-20\% more prediction error early
    \item \textbf{Strategy}: Bet Tuesday/Wednesday, target road underdogs, fade public narratives
  \end{itemize}
  \item \prio{P0} Implementation:
  \begin{itemize}
    \item Create \texttt{py/features/line\_movement\_tracker.py} - Track opening to closing moves
    \item Create \texttt{py/analysis/ewb\_strategy\_backtest.py} - Compare Tuesday vs Sunday bet timing
    \item Create \texttt{R/analysis/line\_movement\_analysis.R} - Visualization (ggplot2)
  \end{itemize}
  \item \prio{P1} \textbf{CLV Analysis}: Validate with Closing Line Value (bets move in our favor → good sign)
  \item \prio{P0} Add dissertation Section 8.4 with backtest results (2010-2024)
  \item \textbf{Target deployment}: Have model predictions ready by Tuesday 12pm ET for line release
\end{itemize}

\block{Task 16: Props Market Extension}
\textbf{Expected EV}: +0.5-1.5\% per prop (higher vig but less competition)

\begin{itemize}
  \item \prio{P1} Analysis (\texttt{docs/reports/props\_market\_analysis.md})
  \begin{itemize}
    \item \textbf{Target props}: Player passing yards (QB), receiving yards (WR), team 1H totals, anytime TD
    \item \textbf{Why props?}: 50-100 props/game, less sharp competition, exploitable public biases
    \item \textbf{Trade-off}: Higher vig (10-15\%) but more volume (3-4$\times$ spreads)
  \end{itemize}
  \item \prio{P1} Implementation:
  \begin{itemize}
    \item Create \texttt{py/models/props\_predictor.py} - Player-level XGBoost model
    \item Create \texttt{py/features/player\_features.py} - Target share, snap count, opponent defense
    \item Create \texttt{R/models/props\_xgboost.R} - Alternative R implementation
  \end{itemize}
  \item \prio{P1} \textbf{Expected performance}: 53-55\% win rate (vs 52.4\% breakeven at -115), 100-200 props/season
  \item \prio{P1} Add dissertation Section 8.5 documenting props modeling approach
\end{itemize}

\block{Task 17: Monitoring \& Risk Management System}
\textbf{Goal}: Automated performance tracking with Thompson switch threshold

\begin{itemize}
  \item \prio{P0} Create \texttt{py/production/monitor\_performance.py} - Track live betting performance
  \begin{itemize}
    \item Input: Bet log CSV (date, game, bet, odds, outcome, profit)
    \item Metrics: Rolling 10-bet, 25-bet win rate, ROI, Sharpe
    \item \textbf{Alerts}: Win rate <55\% over 20 bets → WARNING; <53\% over 25 bets → SWITCH
  \end{itemize}
  \item \prio{P0} Create \texttt{py/production/stress\_test\_monitor.py} - Weekly bootstrap checks
  \begin{itemize}
    \item Run every Sunday after week completes
    \item Resample season-to-date outcomes (1000 MC trials)
    \item \textbf{Alert}: If CVaR(95\%) <-0.5\% → REDUCE BET SIZES
  \end{itemize}
  \item \prio{P0} Create \texttt{py/production/thompson\_switch\_logic.py} - Adaptive ensemble switching
  \begin{itemize}
    \item \textbf{Start}: Majority Voting (71.4\% win rate, conservative)
    \item \textbf{Switch to Thompson}: If win rate >60\% after 25 bets
    \item \textbf{Revert to Majority}: If Thompson win rate <55\% after 20 bets
  \end{itemize}
  \item \prio{P1} Create \texttt{py/viz/production\_dashboard.py} - Streamlit monitoring dashboard
  \begin{itemize}
    \item Bankroll trajectory, rolling win rate, bet size distribution
    \item Upcoming bets table (model recommendations for next week)
  \end{itemize}
  \item \prio{P1} \textbf{Kill switches}: Hard stop if drawdown >10\% of bankroll; model retrain if uncertainty spikes
  \item \prio{P0} Add dissertation Section 8.6 documenting risk management protocols
\end{itemize}

\block{Production Deployment Timeline (8 Weeks)}
\begin{itemize}
  \item \textbf{Week 1}: Deploy majority voting + Kelly sizing → IMMEDIATE betting capability
  \item \textbf{Week 2}: Create 15 Virginia sportsbook accounts + line shopping system
  \item \textbf{Weeks 3-4}: Implement EWB tracking, backtest, dissertation section
  \item \textbf{Weeks 5-6}: Props market models + player features
  \item \textbf{Weeks 7-8}: Build monitoring dashboard + stress test automation
  \item \textbf{Ready for 2025 Season deployment after Week 8}
\end{itemize}

\block{Expected Bankroll Growth (Conservative Estimates)}
\begin{itemize}
  \item \textbf{Year 1 (Majority only)}: \$10,000 → \$10,500-\$11,200 (+5-12\% return)
  \begin{itemize}
    \item Base ROI: +0.36\% (Majority)
    \item + Kelly sizing: +0.2\%
    \item + Line shopping: +0.5\%
    \item + EWB: +0.5\%
    \item \textbf{Total edge}: 1.5-1.8\%
  \end{itemize}
  \item \textbf{Year 2 (with data)}: \$11,200 → \$12,600-\$14,000 (+12-25\% return)
  \begin{itemize}
    \item Year 1 edge: 1.5-1.8\%
    \item + NextGen Stats: +1-2\%
    \item + PFF Elite: +0.5-1\%
    \item \textbf{Total edge}: 3.0-4.8\%
  \end{itemize}
  \item \textbf{Risk limits}: Max drawdown 10\% (\$1,000), max bet 2\% (\$200), min bankroll \$8,000 (pause if hit)
\end{itemize}

\block{Phase 5: Transformer Features + Joint Policy (Weeks 10-11, Priority P1)}
\textbf{Goal}: Model temporal dynamics and multi-game bankroll optimization

\begin{itemize}
  \item \prio{P1} Temporal feature transformer (\texttt{py/models/temporal\_transformer.py}; $\sim$600 LOC)
  \begin{itemize}
    \item Input: last 5-10 games per team (EPA, margin, rest, injuries, opponent)
    \item Output: 256-dim team state embedding
    \item Architectures: small (4L/256D, M4) and large (8L/512D, RTX)
  \end{itemize}
  \item \prio{P1} Multi-game policy transformer (\texttt{py/rl/transformer\_policy.py}; $\sim$600 LOC)
  \begin{itemize}
    \item Allocate bankroll across 12-16 games/week jointly via self-attention
    \item Learn game correlations (e.g., avoid both sides of division matchups)
  \end{itemize}
  \item \prio{P1} \textbf{Validation}: Win rate improvement $\ge$ +0.3\% from temporal modeling
  \item \textbf{Compute}: 200 RTX GPU-hours + 30 M4 GPU-hours
\end{itemize}

\block{Phase 6: Production Monitoring \& Continuous Learning (Weeks 1-12, Priority P0)}
\textbf{Goal}: Maintain edge as market adapts; deploy live system

\begin{itemize}
  \item \prio{P0} Automated retraining pipeline (\texttt{py/pipeline/continuous\_learning.py}; $\sim$400 LOC)
  \begin{itemize}
    \item Trigger: every 4 weeks during season
    \item Workflow: fetch data $\to$ update features $\to$ retrain (light on M4, heavy on RTX) $\to$ OPE $\to$ deploy
  \end{itemize}
  \item \prio{P0} Drift detection \& alerting (\texttt{py/monitoring/drift\_detector.py}; $\sim$300 LOC)
  \begin{itemize}
    \item Monitor: feature KL divergence, weekly Brier, CLV degradation
    \item Alert (Slack/PagerDuty): if Brier $>$ 0.26, CLV $<$ 0, feature drift $>$ 2$\sigma$
  \end{itemize}
  \item \prio{P1} Online learning: incremental model updates with new data (M4-based, lightweight)
  \item \prio{P1} Version control + rollback: immediate if OPE worsens
  \item \textbf{Compute}: 60 GPU-hours spread over 12 weeks (mostly M4)
\end{itemize}

\block{Phase 7: Alternative Market Deployment (Weeks 11-12, Priority P0)}
\textbf{Goal}: Validate edge in lower-vig + alternative markets

\begin{itemize}
  \item \prio{P0} \textbf{QUICK WIN}: Exchange simulation (Betfair, Pinnacle at 2\% vig vs 4.5\%)
  \begin{itemize}
    \item Replay historical bets at 2\% vig (M4-based data analysis, no training)
    \item Current 51.0\% win rate $\to$ \textbf{profitable} at 2\% vig!
    \item Expected ROI: +1.5\% to +2.5\%
    \item Action: 4-week paper trading $\to$ deploy 10-20\% bankroll
  \end{itemize}
  \item \prio{P1} Player props modeling (\texttt{py/models/prop\_predictor.py}; $\sim$500 LOC)
  \begin{itemize}
    \item Passing yards: RNN on QB sequences (RTX, 10h)
    \item Rushing yards: XGBoost on RB usage (M4, 2h)
    \item Anytime TD: Logistic regression (M4, 1h)
    \item Copula correlation: reuse existing framework
  \end{itemize}
  \item \prio{P1} \textbf{Validation}: Props win rate $\ge$ 53\% (literature: props 30\% less efficient)
  \item \textbf{Compute}: 150 RTX GPU-hours + 10 M4 GPU-hours
\end{itemize}

\block{Success Criteria (Post-Dissertation)}
\begin{itemize}
  \item \textbf{Must Achieve (P0)}:
  \begin{itemize}
    \item CQL/IQL agents trained; best config identified via sweep
    \item Ensemble uncertainty filtering reduces bet volume 30\%+, improves win rate 1.5\%+
    \item Neural simulator validates policy across 10K scenarios (CVaR, DD thresholds pass)
    \item Test set win rate $\ge$ 52.5\% (up from 51.0\%)
    \item Positive ROI in exchange simulation (2\% vig): +1.5\% to +3.0\%
  \end{itemize}
  \item \textbf{Should Achieve (P1)}:
  \begin{itemize}
    \item GNN improves ensemble Brier by $\ge$ 0.001
    \item Transformer features improve win rate by $\ge$ +0.3\%
    \item Monitoring pipeline deployed with $<$ 5min drift detection latency
    \item Task queue successfully coordinates M4 + RTX heterogeneously
  \end{itemize}
  \item \textbf{Nice to Have (P2)}:
  \begin{itemize}
    \item Real-money pilot on exchange (small stakes, 4-8 weeks)
    \item Research paper submission (NeurIPS, AISTATS, or sports analytics conference)
    \item Open-source framework release for sports betting research community
  \end{itemize}
\end{itemize}

\block{Compute Budget Summary}
\begin{itemize}
  \item \textbf{Total RTX 5090 GPU-hours}: 1,410 hours (37 days on 2$\times$ GPUs @ 80\% utilization)
  \begin{itemize}
    \item Phase 1 (RL): 900h
    \item Phase 2 (Uncertainty): 200h
    \item Phase 3 (Simulator): 300h
    \item Phase 4 (GNN): 100h
    \item Phase 5 (Transformers): 200h
    \item Phase 6 (Monitoring): 10h
    \item Phase 7 (Props): 150h
  \end{itemize}
  \item \textbf{Total M4 MacBook GPU-hours}: 210 hours (prototyping, light training, validation)
  \item \textbf{Timeline}: 10-12 weeks with parallel M4 development + RTX heavy training
  \item \textbf{Cost Equivalent}: \$45,120 if cloud (AWS p4d.24xlarge); \$0 with owned hardware
\end{itemize}

\milestone{Bayesian Hierarchical Modeling — PRODUCTION READY (October 2025)}

\block{COMPLETED: Bayesian Team Ratings \& Ensemble Integration}
\textbf{Achievement}: Successfully implemented hierarchical Bayesian models showing positive expected value for NFL spread betting.

\textbf{Research Question}: Can Bayesian hierarchical models capture temporal team dynamics better than static ratings (ELO, Glicko) and complement XGBoost predictions for ensemble betting?

\textbf{Answer}: \textcolor{green!60!black}{YES} — Bayesian models are profitable (+1.59\% standalone ROI) and complementary to XGBoost (+2.60\% ensemble ROI when both agree).

\begin{itemize}
  \item \done\ \textbf{Model 1 (Basic)}: margin $\sim$ home + (1$|$home\_team) + (1$|$away\_team)
  \begin{itemize}
    \item LOO-CV ELPD: -11075, No time-varying effects
    \item Baseline hierarchical structure with team random intercepts
  \end{itemize}
  \item \done\ \textbf{Model 2 (Time-Varying)}: margin $\sim$ home + (1+t$|$home) + (1+t$|$away) \textcolor{green!60!black}{✓ BEST}
  \begin{itemize}
    \item LOO-CV ELPD: -11039 (3.3\% improvement over Model 1)
    \item Random slopes capture in-season momentum and team improvement/decline
    \item Temporal smoothing provides complementary signal to XGBoost
  \end{itemize}
  \item \done\ \textbf{Model 3 (Full Attack/Defense)}: margin $\sim$ home + (1+t$|$home\_attack) + (1+t$|$home\_defense) + \dots
  \begin{itemize}
    \item LOO-CV ELPD: -11068 (worse than Model 2 due to overparameterization)
    \item Useful for totals betting (over/under) but not spreads
    \item Demonstrates importance of parsimony with limited NFL data
  \end{itemize}
\end{itemize}

\block{Model Training \& Validation (brms/Stan/cmdstanr)}
\begin{itemize}
  \item \done\ Training data: 2,859 games (2015-2024, regular season + playoffs)
  \item \done\ Test data: 281 games (2024 season) for out-of-sample EV analysis
  \item \done\ Priors: Weakly informative (rating $\sim$ Normal(0, 5), home advantage $\sim$ Normal(2.5, 2))
  \item \done\ Sampling: 2000 iterations (1000 warmup, 1000 posterior), 4 chains, $\hat{R} < 1.01$
  \item \done\ Training time: $<$ 30 seconds per model (Stan GPU acceleration)
  \item \done\ Model comparison: LOO-CV with PSIS diagnostics (all Pareto-k $<$ 0.7)
\end{itemize}

\block{Predictive Performance (2024 Test Set)}
\begin{itemize}
  \item \done\ \textbf{Accuracy}: 52.7\% ATS (163 bets placed, 58\% of games)
  \item \done\ \textbf{Win Rate}: 54.0\% (beats 52.4\% breakeven threshold)
  \item \done\ \textbf{Expected ROI}: +1.59\% (profitable after vig!)
  \item \done\ \textbf{MAE}: 10.52 points (vs market 9.70 points, 8.3\% worse)
  \item \done\ \textbf{Correlation}: 0.307 with actual margins (moderate predictive power)
  \item \done\ \textbf{Market Efficiency}: Better than market 44.2\% of games
\end{itemize}

\block{Ensemble Analysis (Bayesian + XGBoost Synergy)}
\begin{itemize}
  \item \done\ \textbf{Agreement Filtering}: Only bet when both models agree (prob diff $<$ 0.10)
  \item \done\ \textbf{Ensemble Performance}: 55.0\% win rate, +2.60\% ROI (120 bets)
  \item \done\ \textbf{Improvement}: +1.0 pp win rate, +1.01 pp ROI vs standalone Bayesian
  \item \done\ \textbf{Selectivity}: 26\% fewer bets (163 $\to$ 120) but higher quality
  \item \done\ \textbf{XGBoost Comparison}: Bayesian has +0.7 pp accuracy edge over XGBoost v2 baseline
  \item \done\ \textbf{Complementarity}: Bayesian captures temporal dynamics, XGBoost captures game-specific factors
\end{itemize}

\block{Uncertainty Quantification for Risk Management}
\begin{itemize}
  \item \done\ \textbf{Posterior Standard Deviations}: home\_sd, away\_sd, combined\_sd
  \item \done\ \textbf{Calibration}: All 2024 games in "Medium Uncertainty" range (SD 1.3-1.5)
  \item \done\ \textbf{Kelly Sizing}: confidence = 1 / (1 + bayesian\_sd), scales base Kelly fraction
  \item \done\ \textbf{Example}: SD $<$ 1.0 $\to$ bet 1/2 Kelly; SD 1.3-1.5 $\to$ bet 1/4 Kelly; SD $>$ 1.7 $\to$ skip bet
  \item \done\ \textbf{Advantage}: Dynamic position sizing based on model confidence
\end{itemize}

\block{Feature Engineering \& Integration}
\begin{itemize}
  \item \done\ \textbf{Bayesian Features Exported}: 13 new features added to XGBoost pipeline
  \begin{itemize}
    \item home/away\_bayesian\_rating: Posterior mean ratings (points above/below average)
    \item home/away\_bayesian\_sd: Uncertainty quantification
    \item bayesian\_rating\_diff: home - away (primary feature)
    \item bayesian\_combined\_sd: sqrt(home\_sd² + away\_sd²)
    \item bayesian\_confidence: 1 / (1 + combined\_sd)
    \item bayesian\_pred\_margin: rating\_diff + home\_advantage
    \item bayesian\_prob\_home: Normal CDF probability home team wins
  \end{itemize}
  \item \done\ \textbf{Feature Dataset}: \texttt{asof\_team\_features\_v3\_bayesian.csv}
  \begin{itemize}
    \item 5,211 games with 156 features (143 original + 13 Bayesian)
    \item Covers 2006-2024 with as-of-date lineage (no leakage)
  \end{itemize}
  \item \done\ \textbf{Database Integration}: \texttt{mart.bayesian\_team\_ratings} table created
  \begin{itemize}
    \item Schema: team, rating\_mean, rating\_sd, rating\_q05, rating\_q95, model, updated\_at
    \item Weekly updates during season (every Tuesday)
  \end{itemize}
\end{itemize}

\block{Implementation Artifacts}
\begin{itemize}
  \item \done\ \texttt{R/models/bayesian\_hierarchical.R} (brms model training, 350 LOC)
  \item \done\ \texttt{R/bayesian\_ev\_analysis.R} (EV analysis on 2024 test set, 300 LOC)
  \item \done\ \texttt{py/features/bayesian\_features.py} (feature integration module, 266 LOC)
  \item \done\ \texttt{py/production/ensemble\_bayesian\_xgb.py} (ensemble voting system, 484 LOC)
  \item \done\ \texttt{analysis/bayesian\_ev\_findings.md} (comprehensive findings report, 267 lines)
  \item \done\ \texttt{analysis/bayesian\_integration\_summary.md} (implementation guide, 200+ lines)
  \item \done\ \texttt{models/bayesian/time\_varying\_ratings.rds} (trained Stan model with posteriors)
  \item \done\ \texttt{figures/out/bayesian\_model\_comparison.tex} (LaTeX table, 3-model LOO-CV comparison)
  \item \done\ \texttt{figures/out/bayesian\_top\_teams.tex} (LaTeX table, top 10 teams with 90\% credible intervals)
\end{itemize}

\block{Production Deployment Roadmap}
\begin{itemize}
  \item \prio{P0} \textbf{Backtest on 2022-2023}: Validate +2.60\% ensemble ROI on historical seasons using actual XGBoost models
  \item \prio{P0} \textbf{Deploy for live betting}: Start with 25\% Bayesian weight (75\% XGBoost)
  \item \prio{P0} \textbf{Monitor Closing Line Value (CLV)}: Track weekly; if CLV degrades, reduce Bayesian weight
  \item \prio{P0} \textbf{Weekly retraining}: Update Bayesian models every Tuesday with latest results (incremental updates)
  \item \prio{P0} \textbf{Target betting volume}: 8-12 bets per week (120/season at 55\%+ win rate)
  \item \prio{P1} \textbf{Retrain XGBoost v3}: Incorporate 13 Bayesian features for potential +0.3-0.5\% Brier improvement
  \item \prio{P1} \textbf{Expand uncertainty differentiation}: Add game-specific variance (divisional, playoff, weather extremes)
\end{itemize}

\block{Dissertation Integration}
\begin{itemize}
  \item \prio{P0} \textbf{Chapter 4 (Baseline Models)}: Add new Section 4.X "Bayesian Hierarchical Team Ratings"
  \begin{itemize}
    \item Model specifications (Basic, Time-Varying, Full Attack/Defense)
    \item LOO-CV comparison table (\texttt{bayesian\_model\_comparison.tex})
    \item Top teams table with credible intervals (\texttt{bayesian\_top\_teams.tex})
    \item Discussion of hierarchical regularization and temporal dynamics
    \item Comparison to state-space models (Kalman filtering) already in Chapter 4
  \end{itemize}
  \item \prio{P0} \textbf{Chapter 8 (Results)}: Add subsection "Ensemble Voting Strategy"
  \begin{itemize}
    \item 54.0\% $\to$ 55.0\% win rate improvement with agreement filtering
    \item Kelly sizing using Bayesian uncertainty
    \item ROI projections: +1.59\% standalone, +2.60\% ensemble
  \end{itemize}
  \item \prio{P1} \textbf{Appendix}: Include \texttt{R/models/bayesian\_hierarchical.R} code listing
\end{itemize}

\block{Key Findings \& Contributions}
\begin{itemize}
  \item \textbf{Novel Contribution}: First application of brms/Stan hierarchical models to NFL spread betting with uncertainty-based position sizing
  \item \textbf{Complementarity Proof}: Bayesian temporal smoothing complements XGBoost game-specific features (different information)
  \item \textbf{Uncertainty as Signal}: Posterior SDs enable dynamic Kelly sizing (high-confidence bets get larger stakes)
  \item \textbf{Market Efficiency Insight}: Model can be \textit{less accurate than market} (8.3\% worse MAE) but still profitable due to complementary strengths
  \item \textbf{Practical Deployment}: Fast training ($<$ 30 sec), easy weekly updates, seamless PostgreSQL integration
\end{itemize}

\block{Expected ROI Impact (Conservative Estimates)}
\begin{itemize}
  \item \textbf{Scenario 1}: Bayesian as features (15\% weight) $\to$ +0.3\% ROI gain
  \item \textbf{Scenario 2}: Ensemble voting (25\% weight) $\to$ +1.04\% ROI gain
  \item \textbf{Scenario 3}: Full integration (features + voting + Kelly) $\to$ +1.5-2.0\% ROI
  \item \textbf{On \$10,000 bankroll @ 100 bets/season}: \$150-\$200 profit per season
\end{itemize}

\milestone{Phase 6: Narrative \& Qualitative Feature Engineering (12 Weeks)}

\block{MOTIVATION: The "Locker Room Alpha" — Untapped Margin}
\textbf{Hypothesis}: Qualitative information (coaching drama, locker room dynamics, media narratives, player relationships) contains predictive signal that quantitative models miss. This represents a \textbf{huge source of potential margin} because:
\begin{itemize}
  \item \textbf{Market Inefficiency}: Sportsbooks underweight qualitative factors (hard to quantify systematically)
  \item \textbf{Narrative Lag}: Public betting follows media narratives with delay; sentiment can move lines irrationally
  \item \textbf{Coaching Relationships}: Coordinators, position coaches, locker room culture affect performance but aren't in box scores
  \item \textbf{Example Scenarios}:
  \begin{itemize}
    \item QB benched mid-season: Locker room morale collapse (Jets 2024)
    \item Coaching hot seat: Desperate playcalling, increased risk-taking
    \item Player feuds: WR publicly criticizing QB (affects target distribution)
    \item Media pile-on: Public overreaction to single bad game (line movement)
  \end{itemize}
\end{itemize}

\textbf{Expected Gain}: +1.5-3.0\% ROI from qualitative features (literature: sentiment analysis in sports betting shows 2-4\% edges)

\block{Phase 6.1: NLP Sentiment Pipeline (Weeks 1-3)}
\textbf{Goal}: Extract sentiment scores from media articles, tweets, press conferences to quantify "narrative momentum"

\begin{itemize}
  \item \prio{P0} \textbf{Data Sources}:
  \begin{itemize}
    \item ESPN articles (via web scraping): team pages, injury reports, analysis pieces
    \item Twitter/X data (via API): \#NFL, team hashtags, beat reporters, player accounts
    \item Press conferences: NFL.com transcripts, post-game interviews
    \item Reddit r/nfl: Game threads, team subreddits (community sentiment)
  \end{itemize}
  \item \prio{P0} \textbf{NLP Architecture} (\texttt{py/features/sentiment\_pipeline.py}; $\sim$600 LOC):
  \begin{itemize}
    \item \textbf{Transformer Model}: Fine-tune BERT or RoBERTa on sports sentiment corpus
    \item \textbf{Entity Extraction}: spaCy NER for teams, players, coaches
    \item \textbf{Aspect-Based Sentiment}: Separate sentiment for offense, defense, coaching
    \item \textbf{Temporal Aggregation}: Rolling 3-day, 7-day sentiment scores
  \end{itemize}
  \item \prio{P0} \textbf{Features Generated} (12 features):
  \begin{itemize}
    \item team\_sentiment\_3d, team\_sentiment\_7d (positive/negative/neutral distribution)
    \item opponent\_sentiment\_3d, opponent\_sentiment\_7d
    \item sentiment\_momentum: change over past week
    \item sentiment\_variance: disagreement across sources (high variance = uncertainty)
    \item qb\_sentiment, coach\_sentiment (player/coach-specific)
    \item narrative\_polarity: ESPN vs Reddit divergence (public vs sharp perception)
  \end{itemize}
  \item \prio{P1} \textbf{Validation}: Backtest on 2020-2024; expected +0.5-1.0\% ROI improvement
  \item \textbf{Compute}: 50 GPU-hours (RTX, BERT fine-tuning), 10 CPU-hours (scraping/ETL)
\end{itemize}

\block{Phase 6.2: Coaching Relationship Graph (Weeks 4-6)}
\textbf{Goal}: Model coaching trees, coordinator movements, staff turnover to capture organizational dynamics

\begin{itemize}
  \item \prio{P0} \textbf{Data Collection}:
  \begin{itemize}
    \item Coaching history: Pro-Football-Reference scraped data (HC, OC, DC tenure)
    \item Coaching trees: Wikipedia, FiveThirtyEight coaching database
    \item Staff turnover: Track coordinator changes, position coach departures
  \end{itemize}
  \item \prio{P0} \textbf{Graph Construction} (\texttt{py/features/coaching\_graph.py}; $\sim$400 LOC):
  \begin{itemize}
    \item \textbf{Nodes}: Coaches (current and historical), teams
    \item \textbf{Edges}: Mentor-mentee relationships, previous employment, offensive/defensive philosophies
    \item \textbf{Node Features}: Tenure, playoff success, EPA performance under coach
    \item \textbf{Graph Metrics}: Coach centrality, team stability score, coordinator synergy
  \end{itemize}
  \item \prio{P0} \textbf{Features Generated} (8 features):
  \begin{itemize}
    \item coach\_tenure\_weeks: How long current HC has been with team
    \item coordinator\_turnover: Binary flag for new OC/DC this season
    \item coaching\_tree\_overlap: Shared mentor between HC/OC/DC (synergy proxy)
    \item staff\_stability\_score: Weighted sum of position coach tenure
    \item playoff\_experience\_diff: HC playoff wins differential (home vs away)
    \item philosophy\_match: Offensive scheme consistency (West Coast, Air Raid, etc.)
  \end{itemize}
  \item \prio{P1} \textbf{Validation}: Test on coordinator change seasons (expect +0.3-0.5\% ROI)
  \item \textbf{Compute}: Minimal (graph analytics on CPU)
\end{itemize}

\block{Phase 6.3: Locker Room Proxies (Weeks 7-8)}
\textbf{Goal}: Quantify team cohesion, morale, internal conflict through indirect metrics

\begin{itemize}
  \item \prio{P0} \textbf{Proxy Metrics} (\texttt{py/features/locker\_room\_proxies.py}; $\sim$300 LOC):
  \begin{itemize}
    \item \textbf{Contract disputes}: Track holdouts, franchise tag grievances (public sources)
    \item \textbf{Player discipline}: Suspensions, fines, arrests (NFL.com reports)
    \item \textbf{Captains tenure}: How long have team captains been in locker room (stability)
    \item \textbf{Veteran leadership}: Pro Bowl players, playoff experience weighted by snap share
    \item \textbf{Roster turnover}: Percentage of starters new to team this season
    \item \textbf{Media availability}: Track player/coach press conference sentiment (dodging questions = red flag)
  \end{itemize}
  \item \prio{P0} \textbf{Features Generated} (4 features):
  \begin{itemize}
    \item locker\_room\_stability: Composite score (0-100) from captains tenure, roster turnover
    \item discipline\_issues\_4wk: Count of suspensions/fines in last 4 weeks
    \item veteran\_leadership\_score: Weighted playoff experience by snap share
    \item contract\_drama\_binary: Active holdout or franchise tag dispute
  \end{itemize}
  \item \prio{P1} \textbf{Validation}: Backtest on known locker room collapse seasons (2024 Jets, 2022 Broncos)
  \item \textbf{Compute}: Minimal (manual data entry + feature computation)
\end{itemize}

\block{Phase 6.4: Integration \& Validation (Weeks 9-12)}
\begin{itemize}
  \item \prio{P0} Merge all qualitative features into \texttt{asof\_team\_features\_v4\_narrative.csv} (180 features total)
  \item \prio{P0} Retrain XGBoost v4 with narrative features on 2006-2023 training data
  \item \prio{P0} Validate on 2024 test set: Expected Brier $<$ 0.160 (vs 0.164 baseline)
  \item \prio{P0} Feature importance analysis: Identify which qualitative features drive prediction
  \item \prio{P0} Backtest narrative-enhanced ensemble on 2022-2023 seasons
  \item \prio{P1} Create dissertation Section 7.X "Qualitative Feature Engineering"
  \item \textbf{Success Criteria}: Win rate $\ge$ 54\% (up from 52-53\%), ROI $\ge$ +2.5\%
\end{itemize}

\milestone{Phase 7: Super-Ensemble Advanced ML (16 Weeks)}

\block{MOTIVATION: Beyond Single Models — Hierarchical Meta-Learning}
\textbf{Goal}: Combine Bayesian hierarchical models with cutting-edge ML architectures (GNN, GAN, Deep RL) to create a "super-ensemble" that leverages complementary strengths.

\textbf{Key Insight}: No single model architecture dominates NFL betting. Each captures different information:
\begin{itemize}
  \item \textbf{Bayesian Hierarchical}: Temporal dynamics, uncertainty quantification, team evolution
  \item \textbf{XGBoost}: Non-linear feature interactions, game-specific factors
  \item \textbf{GNN}: Team relationship modeling, transitive strength (despite Phase 4 negative result, worth revisiting)
  \item \textbf{GAN}: Synthetic scenario generation for data augmentation
  \item \textbf{Deep RL}: Dynamic betting policy with exploration-exploitation balance
\end{itemize}

\textbf{Expected Performance}: 57-58\% win rate (up from 54-55\%), +4.0-5.0\% ROI (up from +2.6\%)

\block{Phase 7.1: Bayesian-GNN Hybrid (Weeks 1-6)}
\textbf{Goal}: Use Bayesian posteriors as informative priors for GNN node embeddings

\begin{itemize}
  \item \prio{P0} \textbf{Architecture} (\texttt{py/models/bayesian\_gnn\_hybrid.py}; $\sim$700 LOC):
  \begin{itemize}
    \item \textbf{Node Initialization}: Bayesian rating\_mean as node features (32-dim)
    \item \textbf{Uncertainty-Weighted Message Passing}: Edge weights = 1 / (1 + combined\_sd)
    \item Low uncertainty teams have higher influence on graph propagation
    \item \textbf{Temporal GNN}: Graph snapshots per week, edges weighted by recency
    \item \textbf{Prediction Head}: MLP taking GNN embeddings + Bayesian posteriors
  \end{itemize}
  \item \prio{P0} \textbf{Training Strategy}:
  \begin{itemize}
    \item Pre-train GNN on full 2010-2023 game graph
    \item Fine-tune with Bayesian priors from time-varying model
    \item Multi-task learning: predict margin + uncertainty jointly
  \end{itemize}
  \item \prio{P0} \textbf{Validation}: Test on 2024; expected +0.5-1.0\% Brier improvement over standalone GNN
  \item \textbf{Compute}: 150 RTX GPU-hours (GNN training + hyperparameter sweep)
\end{itemize}

\block{Phase 7.2: GAN Scenario Simulator (Weeks 7-10)}
\textbf{Goal}: Generate synthetic game outcomes conditioned on Bayesian context for robust training

\begin{itemize}
  \item \prio{P0} \textbf{Architecture} (\texttt{py/models/bayesian\_gan.py}; $\sim$800 LOC):
  \begin{itemize}
    \item \textbf{Generator}: Conditional GAN taking Bayesian rating\_diff + context (weather, rest, injuries)
    \item Output: Synthetic game margins + play-by-play sequences
    \item \textbf{Discriminator}: Distinguish real vs synthetic games
    \item \textbf{Bayesian Conditioning}: Use rating posteriors to guide generation distribution
  \end{itemize}
  \item \prio{P0} \textbf{Data Augmentation Strategy}:
  \begin{itemize}
    \item Generate 10,000 synthetic games per season (5$\times$ real data)
    \item Oversample rare scenarios: underdog upsets, blowouts, injured QB games
    \item Use synthetic data to train more robust XGBoost/RL models
  \end{itemize}
  \item \prio{P1} \textbf{Counterfactual Analysis}: Generate "what if" scenarios for betting policy stress testing
  \item \prio{P0} \textbf{Validation}: Train XGBoost v5 on real + synthetic data; test on 2024 real games
  \item \textbf{Compute}: 200 RTX GPU-hours (GAN training, 100 epochs)
\end{itemize}

\block{Phase 7.3: Bayesian Deep RL with Thompson Sampling (Weeks 11-14)}
\textbf{Goal}: Use Bayesian posteriors to guide RL exploration-exploitation balance

\begin{itemize}
  \item \prio{P0} \textbf{Architecture} (\texttt{py/rl/bayesian\_thompson\_rl.py}; $\sim$600 LOC):
  \begin{itemize}
    \item \textbf{Thompson Sampling}: Sample from Bayesian posterior distributions for Q-value uncertainty
    \item \textbf{Action Space}: [no\_bet, bet\_small, bet\_medium, bet\_large] (4 actions)
    \item \textbf{State Space}: Bayesian ratings + XGBoost features + market odds + bankroll state
    \item \textbf{Reward}: PnL with CVaR penalty (discourage high-variance strategies)
  \end{itemize}
  \item \prio{P0} \textbf{Exploration Strategy}:
  \begin{itemize}
    \item Sample team ratings from Bayesian posteriors (1000 draws per game)
    \item For each draw, compute Q-value; take mean as expected return
    \item High uncertainty games $\to$ more exploration (try diverse actions)
  \end{itemize}
  \item \prio{P0} \textbf{Training}: Offline RL on 2006-2023 games + GAN synthetic data
  \item \prio{P0} \textbf{Validation}: OPE on 2024 test set; expected +0.5-1.0\% ROI vs CQL baseline
  \item \textbf{Compute}: 180 RTX GPU-hours (deep Q-network training)
\end{itemize}

\block{Phase 7.4: Hierarchical Meta-Learner (Weeks 15-16)}
\textbf{Goal}: Stack all models (Bayesian, XGBoost, GNN, GAN-augmented, Deep RL) into super-ensemble

\begin{itemize}
  \item \prio{P0} \textbf{Architecture} (\texttt{py/models/meta\_learner.py}; $\sim$500 LOC):
  \begin{itemize}
    \item \textbf{Level 0 (Base Models)}: 5 models generate predictions
    \begin{enumerate}
      \item Bayesian hierarchical (time-varying)
      \item XGBoost v4 (with narrative features)
      \item Bayesian-GNN hybrid
      \item XGBoost v5 (trained on GAN synthetic data)
      \item Bayesian Deep RL policy
    \end{enumerate}
    \item \textbf{Level 1 (Meta-Model)}: Logistic regression or LightGBM taking base predictions + uncertainties
    \item \textbf{Dynamic Weighting}: Learn optimal weights per game context (home/away, divisional, weather)
  \end{itemize}
  \item \prio{P0} \textbf{Training Strategy}:
  \begin{itemize}
    \item Train level-0 models on 2006-2021 data
    \item Train meta-model on 2022-2023 validation data (out-of-sample base predictions)
    \item Final test on 2024 holdout set
  \end{itemize}
  \item \prio{P0} \textbf{Bet Selection Logic}:
  \begin{itemize}
    \item Bet IFF: meta-model prediction $>$ threshold AND $\ge$ 4/5 base models agree
    \item Use Bayesian uncertainty for Kelly sizing
    \item Expected selectivity: 80-100 bets/season (30\% of games)
  \end{itemize}
  \item \prio{P0} \textbf{Validation}: Full backtest on 2022-2024; stress test with Monte Carlo
  \item \textbf{Success Criteria}:
  \begin{itemize}
    \item Win rate $\ge$ 57\% (up from 54-55\%)
    \item ROI $\ge$ +4.0\% (up from +2.6\%)
    \item Sharpe ratio $\ge$ +1.0 (up from +0.4)
    \item Max drawdown $<$ 8\% over 1000 simulated seasons
  \end{itemize}
  \item \textbf{Compute}: 50 GPU-hours (meta-model training + validation)
\end{itemize}

\block{Phase 7.5: OPE Safety Gate (Week 16)}
\begin{itemize}
  \item \prio{P0} Off-Policy Evaluation on 2022-2024 test sets using DR/HCOPE estimators
  \item \prio{P0} Bootstrap confidence intervals (1000 trials): Verify 95\% CI excludes negative ROI
  \item \prio{P0} Stress testing: 10,000 Monte Carlo seasons with worst-case scenarios
  \item \prio{P0} CVaR(95\%) threshold: Must be $\ge$ -2\% (acceptable tail risk)
  \item \prio{P0} Model registry: Checkpoint super-ensemble for production deployment
  \item \prio{P0} Monitoring setup: Real-time performance tracking with drift detection
  \item \textbf{GO/NO-GO Decision}: Only deploy if all safety gates pass
\end{itemize}

\block{Expected Timeline \& Milestones}
\begin{itemize}
  \item \textbf{Weeks 1-3}: NLP sentiment pipeline $\to$ 12 features
  \item \textbf{Weeks 4-6}: Coaching graph $\to$ 8 features
  \item \textbf{Weeks 7-8}: Locker room proxies $\to$ 4 features
  \item \textbf{Weeks 9-12}: Integration + validation $\to$ XGBoost v4 (180 features)
  \item \textbf{Weeks 13-18}: Bayesian-GNN hybrid $\to$ +0.5-1.0\% Brier
  \item \textbf{Weeks 19-22}: GAN scenario simulator $\to$ 10K synthetic games
  \item \textbf{Weeks 23-26}: Bayesian Deep RL $\to$ Thompson Sampling policy
  \item \textbf{Weeks 27-28}: Super-ensemble meta-learner $\to$ 57\%+ win rate
  \item \textbf{Total Duration}: 28 weeks (7 months)
\end{itemize}

\block{Expected ROI Waterfall (Conservative Estimates)}
\begin{itemize}
  \item \textbf{Current Baseline (Oct 2025)}: XGBoost v2 + Bayesian ensemble $\to$ +2.6\% ROI, 55\% win rate
  \item \textbf{+ Narrative Features}: +1.5-2.0\% ROI gain $\to$ +4.1-4.6\% ROI total
  \item \textbf{+ Bayesian-GNN Hybrid}: +0.5\% ROI gain $\to$ +4.6-5.1\% ROI
  \item \textbf{+ GAN Augmentation}: +0.3\% ROI gain $\to$ +4.9-5.4\% ROI
  \item \textbf{+ Bayesian Deep RL}: +0.5\% ROI gain $\to$ +5.4-5.9\% ROI
  \item \textbf{Target Super-Ensemble}: 57-58\% win rate, +5.0-6.0\% ROI
  \item \textbf{On \$10,000 bankroll @ 80 bets/season}: \$400-\$480 profit per season
\end{itemize}

\endgroup
